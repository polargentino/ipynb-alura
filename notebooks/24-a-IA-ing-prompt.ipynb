{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5bab8cae",
   "metadata": {},
   "source": [
    "# Curso de Ingeniería de Prompt: creando prompts eficaces para la IA generativa\n",
    "\n",
    "## Realice este curso para IA para Datos y:\n",
    "* Realizar interacciones con la API de ChatGPT\n",
    "* Manipule fuentes de claves de la API ChatGPT\n",
    "* Aprenda a configurar los parámetros de ChatGPT\n",
    "* Aprende los conceptos de Asistentes y Threads en el Playground\n",
    "* Entiende lo que es la ingeniería de Prompt y prompt template\n",
    "* Conozca el procesamiento de información por lotes y cómo se hace\n",
    "\n",
    "### Aulas:\n",
    "* ## Conceptos iniciales Ver el primer video 0 / 7 35min\n",
    "* ## Ingeniería de Prompt 0 / 7 15min\n",
    "* ## Few-shot y Chain-of-Thought Prompt 0 / 8 18min\n",
    "* ## Más técnicas 0 / 9 26min\n",
    "\n",
    "# 01 Presentación\n",
    "¡Hola! En esta clase de introducción al curso de Ingeniería de Prompt, Christian Velasco nos presenta un panorama general de lo que aprenderemos.Imagina que los LLM (Modelos de Lenguaje Grande) son como genios de la lámpara maravillosa. Tú eres Aladino, y el \"prompt\" es tu deseo. Si formulas mal tu deseo, el genio te dará algo que no querías. La Ingeniería de Prompt es como aprender a hablar el idioma de los genios para que tus deseos se hagan realidad tal como los imaginas.En este curso, aprenderás las técnicas y trucos para comunicarte eficazmente con estos \"genios\" de la IA, para que puedas obtener respuestas precisas y útiles. No importa si eres programador o no, ¡todos podemos convertirnos en expertos en pedir deseos a la IA!¿Te gustaría que te diera otro ejemplo o analogía para entender mejor algún punto en específico?\n",
    "\n",
    "# 02 Preparando el ambiente\n",
    "Antes de comenzar…\n",
    "Durante el curso, utilizaremos diferentes herramientas de Inteligencia Artificial Generativa.\n",
    "\n",
    "En esta clase, utilizaremos ChatGPT, una herramienta disponible en la página de OpenAI. Para comenzar a usarla, es necesario crear una cuenta en OpenAI.\n",
    "\n",
    "Si aún no tienes una cuenta, simplemente haz clic en la opción \"Sign up\" o “Registrar” en la página de inicio y, a continuación, elige entre crear una cuenta o utilizar una cuenta de Google o Microsoft; si eliges la segunda opción, será necesario permitir que OpenAI acceda a tu información.\n",
    "\n",
    "Después de iniciar sesión, a continuación se presentan algunos pasos para comenzar a usar ChatGPT:\n",
    "\n",
    "1 - Escribe tu primer mensaje en el cuadro de texto y presiona \"Enviar\". Por ejemplo: puedes comenzar con un simple \"Hola\" o hacer una pregunta.\n",
    "\n",
    "2 - ChatGPT responderá automáticamente a tu mensaje con una respuesta generada por inteligencia artificial. A partir de ahí, puedes continuar la conversación haciendo más preguntas o respondiendo a las preguntas de ChatGPT.\n",
    "\n",
    "3 - Experimenta con diferentes tipos de preguntas o temas para ver de qué es capaz ChatGPT. Puedes preguntar sobre un tema específico, pedir ayuda con una tarea o simplemente conversar con ChatGPT.\n",
    "\n",
    "Si deseas cambiar de tema y comenzar una nueva conversación en cualquier momento, simplemente haz clic en la opción \"New chat\" (nueva conversación) en el menú lateral izquierdo.\n",
    "\n",
    "Para seguir este curso, puedes utilizar tanto la versión gratuita como la versión de pago, llamada \"Plus\".\n",
    "\n",
    "También utilizaremos el playground de OpenAI. Sin embargo, esta es una funcionalidad de pago. Para esta actividad, es posible utilizar el AI Studio, el playground del modelo Gemini de Google. Para utilizarlo, solo necesitas tener una cuenta de Gmail.\n",
    "\n",
    "Ahora que ya sabes cómo utilizar ChatGPT, ¡podemos comenzar!\n",
    "\n",
    "# 03 Proximidad Semántica\n",
    "¡Hola! En esta clase, Christian Velasco nos introduce a la Ingeniería de Prompt, una técnica clave para interactuar eficazmente con los LLMs (Large Language Models). Aquí tienes un resumen conciso de los puntos principales:\n",
    "¿Qué es la Ingeniería de Prompt? Es el arte de crear requisiciones claras y efectivas para obtener respuestas útiles de los modelos de lenguaje.\n",
    "* Modelos de Lenguaje (LLMs): Son algoritmos entrenados con grandes cantidades de datos para entender el lenguaje humano y resolver problemas.\n",
    "* Proximidad Semántica: Es una técnica que muestra cómo las palabras se relacionan entre sí en función de su uso común. Palabras que a menudo aparecen juntas tienen una alta proximidad semántica.\n",
    "* Word Embeddings: Representaciones matemáticas de palabras que capturan sus relaciones semánticas. Esto permite a los modelos entender analogías y predecir palabras en una oración.\n",
    "* Contexto en LLMs: Los LLMs tienen una \"memoria\" que les permite mantener el contexto de una conversación, lo que facilita interacciones más naturales.\n",
    "\n",
    "¿Te gustaría que profundizáramos en alguno de estos puntos o tienes alguna pregunta específica?\n",
    "\n",
    "#  04 Word embeddings\n",
    "Nathália es una desarrolladora que trabaja en una editorial de libros de tecnología. Ella está construyendo una solución basada en Inteligencia Artificial que haga sugerencias de nuevos libros para lectores que ya son clientes de la editorial.\n",
    "\n",
    "Para iniciar su proyecto, Nathália está aprendiendo sobre word embeddings y quedó impresionada por cómo las palabras son representadas y agrupadas en el espacio de embeddings.\n",
    "\n",
    "![prompt.png](/home/pol/Escritorio/ipynb-alura/assets/prompt.png)\n",
    "\n",
    "## En relación con la distribución de las palabras en este espacio, ¿cuáles afirmaciones son verdaderas?\n",
    "\n",
    "* Alternativa correta\n",
    "**Las palabras que comparten un significado muy cercano, como “calor” y “caliente”, están cerca en el espacio de embeddings.**\n",
    "\n",
    "\n",
    "Como \"calor\" y \"caliente\" se utilizan frecuentemente en contextos similares y tienen significados relacionados, sus embeddings terminan siendo similares, reflejando esta proximidad semántica.\n",
    "\n",
    "* Alternativa correta\n",
    "**Las palabras que pertenecen a la misma categoría gramatical, como sustantivos o verbos, están siempre cerca en el espacio de embeddings.**\n",
    "\n",
    "\n",
    "* Alternativa correta\n",
    "**Las palabras que suelen aparecer juntas en frases están más cerca en el espacio de embeddings.**\n",
    "\n",
    "\n",
    "Los modelos de lenguaje de gran tamaño son entrenados con base en una cantidad muy grande de texto y aprenden sobre la semántica de las palabras y sobre el contexto a partir de la coocurrencia de palabras en los textos de entrenamiento. Cuando las palabras se utilizan frecuentemente juntas, el modelo de embeddings \"aprende\" que tienen una relación contextual fuerte, resultando en `representaciones numérsicas (embeddings)` que están más cercanas entre sí.\n",
    "\n",
    "* Alternativa correta\n",
    "**Las palabras que tienen el opuesto de significado una de la otra están necesariamente muy distantes en el espacio de embeddings.**\n",
    "\n",
    "# 05 Temperatura y Tokens\n",
    "¡Hola! En esta clase, exploramos los conceptos de temperatura y tokens en la ingeniería de prompts. Aquí te presento algunas analogías para ayudarte a comprender mejor estos conceptos:\n",
    "Temperatura como un termostato para la creatividad:\n",
    "Imagina que la temperatura es como un termostato que controla la creatividad de un chef. Si ajustas el termostato a una temperatura baja (cercana a 0), el chef seguirá una receta al pie de la letra, siendo muy preciso y determinista en su cocina. Pero si subes la temperatura (cercana a 2), el chef se sentirá más libre para experimentar, añadir ingredientes inesperados y crear platos únicos, aunque a veces pueda resultar en algo no tan sabroso.\n",
    "\n",
    "\n",
    "Tokens como las piezas de un rompecabezas:\n",
    "Piensa en los tokens como las piezas de un rompecabezas. Cada palabra o parte de una palabra es una pieza. En algunos idiomas, como el inglés, las piezas son más grandes (una palabra puede ser una pieza), mientras que en otros, como el español, las piezas son más pequeñas (una palabra puede dividirse en varias piezas). Cuantas más piezas tenga un rompecabezas, más información necesita el modelo para entender la imagen completa.\n",
    "\n",
    "\n",
    "Tokens como el combustible de un coche:\n",
    "Considera los tokens como el combustible que necesita un coche para funcionar. Cada vez que envías un prompt a un modelo de lenguaje, estás gastando \"combustible\" (tokens). Algunos modelos son más eficientes y utilizan menos combustible por kilómetro recorrido (entienden mejor con menos tokens), mientras que otros necesitan más combustible para el mismo recorrido. Además, cada modelo tiene un límite de combustible que puede gastar, y si te pasas, tendrás que pagar más.\n",
    "\n",
    "\n",
    "\n",
    "Espero que estas analogías te ayuden a comprender mejor los conceptos de temperatura y tokens. ¿Te gustaría que profundizáramos en alguno de estos temas o tienes alguna otra pregunta?\n",
    "\n",
    "\n",
    "#  06 Hazlo como yo lo hice: explorando probabilidades\n",
    "En esta clase, descubrimos cómo los modelos de lenguaje de gran escala, como ChatGPT, comprenden y generan texto.\n",
    "\n",
    "Estos modelos son entrenados con una cantidad muy grande de textos y, durante el entrenamiento, van creando “comprensiones matemáticas” sobre lenguaje, semántica y significado.\n",
    "\n",
    "Cuando enviamos una instrucción al modelo, el texto se divide primero en tokens y luego se convierte en embeddings. Cada embedding es un valor numérico que representa la palabra en un espacio matemático, donde todo el vocabulario del modelo está organizado de acuerdo con el contexto.\n",
    "\n",
    "Entonces, el modelo genera una palabra a la vez, calculando cuál es la próxima palabra más probable en el contexto de la respuesta.\n",
    "\n",
    "También vimos el concepto de temperatura aplicado en la IA generativa: la temperatura es un parámetro que permite controlar si el modelo elegirá la palabra más probable y creará una respuesta robótica, o elegirá palabras con menor probabilidad y creará respuestas más creativas.\n",
    "\n",
    "¡Ahora es tu turno!\n",
    "Envía el prompt a continuación a ChatGPT y luego envía alguna frase incompleta para que él responda con las probabilidades. Experimenta con diversas frases para comprender mejor cómo se eligen las palabras en el momento de la generación de texto.\n",
    "\n",
    "Vamos a simular cómo funciona ChatGPT. Para cada frase que yo escriba en el prompt, debes listar las 5 palabras con mayor probabilidad que usarías para completarla, junto con la probabilidad de cada una de ellas. ¿De acuerdo? Solo las palabras y probabilidades, sin más nada. Dime si entendiste.\n",
    "Copia el código\n",
    "También puedes ajustar la temperatura en el playground del modelo para experimentar cómo funciona la generación de texto con diferentes valores de este parámetro.\n",
    "\n",
    "Consejo: OpenAI, la empresa que desarrolló ChatGPT, no ofrece un nivel gratuito de uso del playground. Para esta actividad, puedes utilizar el AI Studio, el playground del modelo Gemini, de Google. Para utilizarlo, solo necesitas tener una cuenta de Gmail. ¡Diviértete!\n",
    "\n",
    "Explora también el tokenizador de OpenAI.\n",
    "\n",
    "# Opinión del instructor\n",
    "\n",
    "Una experiencia divertida puede ser crear una frase con las palabras menos probables sugeridas por ChatGPT. Solo cambiando la palabra mayor por menor en el prompt que utilizamos en la simulación, así:\n",
    "\n",
    "Vamos a simular cómo funciona ChatGPT. Para cada frase que yo escriba en el prompt, debes listar las 5 palabras con menor probabilidad que usarías para completarla, junto con la probabilidad de cada una de ellas. ¿De acuerdo? Solo las palabras y probabilidades, sin más nada. Dime si entendiste.\n",
    "\n",
    "Al enviar la frase “Me gusta bucear en”, la mayor probabilidad de continuación sería “mar”, la segunda, “río”. Pero, pidiendo las menores probabilidades, tenemos como respuesta solo palabras que no tienen ninguna relación con el buceo:\n",
    "\n",
    "elefante - 0.00001%\n",
    "\n",
    "contenedor - 0.00002%\n",
    "\n",
    "camión - 0.00003%\n",
    "\n",
    "satélite - 0.00004%\n",
    "\n",
    "uranio - 0.00005%\n",
    "\n",
    "Comprender conceptos que explican cómo funcionan los modelos de lenguaje es un paso importante para aprender a sacar el mejor provecho de esta tecnología. En la próxima clase, conoceremos qué es la famosa Ingeniería de Prompt. ¡Vamos!\n",
    "\n",
    "#  07 ¿Qué aprendimos?\n",
    "En esta clase, aprendiste a:\n",
    "\n",
    "* Conceptualizar cómo las palabras son representadas en el modelo a través de word embeddings y tokens;\n",
    "* Identificar cómo las palabras se relacionan a través de la semántica en un modelo de lenguaje;\n",
    "* Simular el funcionamiento del modelo de lenguaje visualizando probabilidades;\n",
    "* Explorar el parámetro de temperatura en el playground de OpenAI.\n",
    "\n",
    "----------\n",
    "# 2 - Ing. de Prompts\n",
    "\n",
    "# 01 ¿Qué es Ingeniería de Prompt?\n",
    "\n",
    "¡Hola! En esta clase, exploramos la importancia de la Ingeniería de Prompt y cómo crear prompts efectivos para obtener resultados más asertivos de los modelos de lenguaje como Gemini.Aquí tienes un resumen de los puntos clave:\n",
    "* Ingeniería de Prompt: No es una ciencia exacta, pero se basa en buenas prácticas y fundamentos para extraer valor de los LLMs.\n",
    "* Caso Práctico: Se utilizó el ejemplo de crear un post para Instagram sobre inteligencia artificial para demostrar la diferencia entre un prompt genérico y uno específico.\n",
    "* Prompt Genérico vs. Prompt Mejorado: Un prompt genérico produce respuestas genéricas, mientras que un prompt con más contexto y detalles genera resultados más adecuados y asertivos.\n",
    "* Ejemplo de Prompt Mejorado: Se proporcionó un prompt detallado que especificaba el formato, el lenguaje y el público objetivo del post de Instagram, lo que resultó en un texto más atractivo y relevante.\n",
    "* Importancia de las Buenas Prácticas: Existen técnicas que se pueden implementar para asegurar que los resultados sean repetibles y que atiendan las necesidades del usuario.\n",
    "\n",
    "En resumen, la clave para obtener buenos resultados de los LLMs es proporcionar prompts específicos y bien definidos que tengan en cuenta el contexto, el público objetivo y el formato deseado.¿Te gustaría que profundizáramos en algún aspecto en particular?\n",
    "\n",
    "#  02 Para saber más: motivando la acción\n",
    "Contenido: El término prompt es conocido desde hace tiempo por personas que trabajan en el área de tecnología. El “Símbolo del sistema” de Windows, por ejemplo, es una interfaz que recibe códigos que ejecutan funciones administrativas avanzadas en el sistema operativo. En el área de la computación, este término se ha utilizado desde las primeras interacciones de usuarios con máquinas a través de texto.\n",
    "\n",
    "Pero… ¿qué significa esta palabra?\n",
    "\n",
    "En traducción literal del inglés, prompt significa “incitar” o “inducir”, “hacer que algo suceda”, “motivar”. Es un verbo que indica que algún movimiento está a punto de suceder.\n",
    "\n",
    "Cuando una interfaz presenta un prompt para la persona usuaria, es exactamente eso lo que está sucediendo: el programa nos está “provocando” a hacer una solicitud a través de la línea de comandos. Cuando enviamos el comando, devolvemos el incentivo, y esto inicia la interacción entre la persona y la máquina.\n",
    "\n",
    "En el contexto de modelos de lenguaje e inteligencia artificial, el prompt es fundamental y permite que la interacción se asemeje a una conversación, con el uso de lenguaje natural.\n",
    "\n",
    "Por lo tanto, crear un buen prompt para interactuar con un modelo de lenguaje requiere técnicas que comprendan el funcionamiento de esta tecnología, así como en la comunicación humana: es importante conocer al público objetivo para adaptar el discurso en una charla, por ejemplo. De la misma manera, es importante conocer los fundamentos de un modelo de lenguaje para adaptar la comunicación y obtener buenos resultados.\n",
    "\n",
    "#  03 Preparando el ambiente\n",
    "En la siguiente clase, utilizaremos el modelo de lenguaje Gemini de Google. Puedes usar cualquier modelo que prefieras para seguir la clase, pero, si deseas conocer Gemini, es necesario acceder a la plataforma.\n",
    "\n",
    "Para comenzar, solo necesitas una cuenta de Google. Inicia sesión con tu cuenta existente o, si aún no tienes una, puedes crear una nueva de forma gratuita.\n",
    "\n",
    "# 04 Principios y Frameworks\n",
    "¡Hola! En esta clase, aprendimos sobre los principios para diseñar un prompt ideal y cómo los frameworks pueden ayudarnos a estructurarlos de manera efectiva.Aquí tienes un resumen de los puntos clave:\n",
    "## Principios para un Prompt Ideal:\n",
    "* Claridad en las instrucciones: Ser lo más claro y específico posible al escribir el prompt.\n",
    "* Dividir tareas complejas: Descomponer problemas grandes en subtareas más pequeñas para obtener resultados más precisos.\n",
    "* Explicaciones paso a paso: Pedir al LLM que explique el proceso antes de dar la respuesta, especialmente en ejercicios de lógica.\n",
    "* Justificaciones para las respuestas: Solicitar que se justifiquen las respuestas, sobre todo al trabajar con información basada en hechos.\n",
    "* Generación de múltiples respuestas: Generar varias respuestas diferentes y elegir la mejor opción, útil para generar ideas.\n",
    "\n",
    "\n",
    "## Frameworks para Generar Prompts:\n",
    "* Clear: Contexto, Longitud, Expectativa, Acción y Resultado.\n",
    "* Smart: Específico, Medible, Alcanzable, Relevante y con un horizonte de Tiempo definido.\n",
    "* Ideal y Brief: Otros frameworks que se pueden aplicar a diferentes situaciones.\n",
    "\n",
    "\n",
    "## Ejemplo Práctico con Clear:\n",
    "Se desarrolló un prompt utilizando el framework Clear para generar ideas de campañas de marketing para una aplicación de comida a domicilio.\n",
    "Se probó el prompt en ChatGPT, obteniendo cinco ideas concretas que podrían aumentar las descargas de la aplicación.\n",
    "\n",
    "\n",
    "\n",
    "¿Te gustaría que profundicemos en alguno de estos puntos o tienes alguna pregunta específica?\n",
    "\n",
    "#  05 Comunicando instrucciones\n",
    "María Isabel, una ingeniera de datos senior, necesita orientar a un pasante que acaba de llegar a la empresa. Ella sabe que, para hacerse entender, es necesario tomar algunas precauciones en la forma en que comunica las tareas, especialmente las más complejas.\n",
    "\n",
    "Estas mismas precauciones son recomendadas al escribir comandos para una IA generativa.\n",
    "\n",
    "¿Cuáles de los siguientes elementos son importantes tanto en la comunicación con el pasante como en la creación de prompts para una IA generativa?\n",
    "\n",
    "Usar términos técnicos complejos para garantizar precisión en la comunicación.\n",
    "\n",
    "\n",
    "* Alternativa incorreta\n",
    "Incluir detalles personales en la explicación, creando una relación amigable para que el pasante se sienta a gusto.\n",
    "\n",
    "\n",
    "* Alternativa correcta\n",
    "Hablar las instrucciones con claridad, dividir tareas complejas en subtareas más pequeñas y explicar el razonamiento detrás de las instrucciones.\n",
    "\n",
    "Estos elementos son fundamentales para evitar malentendidos en la comunicación y mejorar la precisión y, por lo tanto, obtener resultados más asertivos. Claridad, explicación y división de tareas complejas en tareas más pequeñas funcionan bien tanto al enseñar a una persona aprendiz como al dar instrucciones a la IA.\n",
    "\n",
    "Alternativa incorreta\n",
    "Permitir flexibilidad en las respuestas, dejando espacio para la interpretación.\n",
    "\n",
    "\n",
    "#  06 Haz como yo hice: principios fundamentales\n",
    "En esta clase, vimos algunos principios generales de la Ingeniería de Prompt: el acto de construir cuidadosamente un comando eficaz para extraer el mejor resultado posible de una IA generativa.\n",
    "\n",
    "Estas directrices han demostrado ser efectivas para mejorar la calidad de las respuestas. Las principales son:\n",
    "\n",
    "* Tener claridad al dar las instrucciones;\n",
    "* Dividir tareas complejas en subtareas más pequeñas;\n",
    "* Pedir al modelo que explique sus pasos antes de dar la respuesta;\n",
    "* Pedir al modelo que justifique sus respuestas;\n",
    "* Generar varias respuestas diferentes y pedir al modelo que elija la mejor.\n",
    "\n",
    "\n",
    "## Practica tú también!\n",
    "El siguiente prompt contiene las pistas del juego de detective y las alternativas “Sí”, “No” y “Desconocido”.\n",
    "\n",
    "Usa las siguientes pistas para responder a la siguiente pregunta de opción múltiple.\n",
    "\n",
    "Pistas:\n",
    "1. La Señorita Scarlett era la única persona en la sala.\n",
    "2. La persona con la pipa estaba en la cocina.\n",
    "3. El Coronel Mostaza era la única persona en el observatorio.\n",
    "4. El Profesor Ciruela no estaba en la biblioteca ni en la sala de billar.\n",
    "5. La persona con el candelabro estaba en el observatorio.\n",
    "\n",
    "Pregunta: ¿El Coronel Mostaza estaba en el observatorio con el candelabro? \n",
    "(a) Sí; El Coronel Mostaza estaba en el observatorio con el candelabro\n",
    "(b) No; El Coronel Mostaza no estaba en el observatorio con el candelabro\n",
    "(c) Desconocido, no hay suficiente información para determinar si el Coronel Mostaza estaba en el observatorio con el candelabro\n",
    "\n",
    "Respuesta:______________\n",
    "\n",
    "* Prueba también, en otro chat, el mismo juego, pero aplicando algunos principios de la ingeniería de prompt.\n",
    "\n",
    "Usa las siguientes pistas para responder a la siguiente pregunta de opción múltiple, utilizando el siguiente procedimiento:\n",
    "\n",
    "(1) Primero, analiza las pistas una por una y considera si la pista es potencialmente relevante\n",
    "(2) En segundo lugar, combina las pistas relevantes para razonar la respuesta correcta a la pregunta\n",
    "(3) En tercer lugar, mapea la respuesta a una de las respuestas de opción múltiple: (a), (b) o (c)\n",
    "\n",
    "Pistas:\n",
    "1. La Señorita Scarlett era la única persona en la sala.\n",
    "2. La persona con la pipa estaba en la cocina.\n",
    "3. El Coronel Mostaza era la única persona en el observatorio.\n",
    "4. El Profesor Ciruela no estaba en la biblioteca ni en la sala de billar.\n",
    "5. La persona con el candelabro estaba en el observatorio.\n",
    "\n",
    "Pregunta: ¿El Coronel Mostaza estaba en el observatorio con el candelabro? \n",
    "(a) Sí; El Coronel Mostaza estaba en el observatorio con el candelabro\n",
    "(b) No; El Coronel Mostaza no estaba en el observatorio con el candelabro\n",
    "(c) Desconocido, no hay suficiente información para determinar si el Coronel Mostaza estaba en el observatorio con el candelabro\n",
    "\n",
    "Respuesta:______________\n",
    "\n",
    "En este último prompt, dividimos la tarea principal en subtareas, y la instrucción se volvió más clara, en consecuencia. Compara los resultados y prueba en diferentes modelos. También es interesante probar en tareas de tu día a día que no obtuvieron resultados satisfactorios anteriormente.\n",
    "\n",
    "\n",
    "# Opinión del instructor\n",
    "\n",
    "En el momento en que estás haciendo este curso, puede ser que los modelos de lenguaje actuales ya estén mucho más preparados para responder al enigma del Coronel Mostaza, incluso sin las especificidades de las orientaciones del segundo prompt. ¡Eso es genial!\n",
    "\n",
    "El área de IA se mueve con mucha rapidez y los modelos están en constante mejora. El ChatGPT 4, por ejemplo, que fue lanzado en 2024, tiene alrededor de 170 billones de parámetros en su entrenamiento, y ya ha sido perfeccionado por las experimentaciones científicas realizadas con los modelos que vinieron antes de él.\n",
    "\n",
    "Como comparación, el modelo 3.5 (el que fue lanzado en 2022 y trajo el tema de IA a la luz), tenía 170 mil millones de parámetros. ¡Es decir, el modelo 4 tiene un “conocimiento” mil veces mayor que su modelo anterior! Este salto impresionante impacta considerablemente en la capacidad del modelo.\n",
    "\n",
    "Sin embargo, la mejora en la capacidad de los modelos no nos exime de conocer las técnicas de ingeniería de prompt, ¡todo lo contrario! A medida que la tecnología avanza en complejidad, es imperativo que nosotros, las personas que usamos estas tecnologías, avancemos en nuestra comprensión sobre ellas también.\n",
    "\n",
    "#  07 ¿Qué aprendimos?\n",
    "En esta clase, aprendiste:\n",
    "\n",
    "* Lo que significa el término “Ingeniería de Prompt”;\n",
    "* Las principales recomendaciones para crear un prompt eficaz.\n",
    "\n",
    "----------\n",
    "\n",
    "# 3 - Few-shot y chain-of-Thought Prompt\n",
    "## Preparando el ambiente\n",
    "En la siguiente clase, utilizaremos el modelo de lenguaje DeepSeek. Puedes usar cualquier modelo que prefieras para seguir la clase, pero, si deseas conocer DeepSeek, es necesario acceder a la plataforma.\n",
    "\n",
    "Para comenzar, puedes iniciar sesión con tu cuenta de Google o Microsoft. Si aún no tienes una cuenta, puedes registrarte fácilmente en la plataforma.\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
