{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5bab8cae",
   "metadata": {},
   "source": [
    "# Curso de Ingeniería de Prompt: creando prompts eficaces para la IA generativa\n",
    "\n",
    "## Realice este curso para IA para Datos y:\n",
    "* Realizar interacciones con la API de ChatGPT\n",
    "* Manipule fuentes de claves de la API ChatGPT\n",
    "* Aprenda a configurar los parámetros de ChatGPT\n",
    "* Aprende los conceptos de Asistentes y Threads en el Playground\n",
    "* Entiende lo que es la ingeniería de Prompt y prompt template\n",
    "* Conozca el procesamiento de información por lotes y cómo se hace\n",
    "\n",
    "### Aulas:\n",
    "* ## Conceptos iniciales Ver el primer video 0 / 7 35min\n",
    "* ## Ingeniería de Prompt 0 / 7 15min\n",
    "* ## Few-shot y Chain-of-Thought Prompt 0 / 8 18min\n",
    "* ## Más técnicas 0 / 9 26min\n",
    "\n",
    "# 01 Presentación\n",
    "¡Hola! En esta clase de introducción al curso de Ingeniería de Prompt, Christian Velasco nos presenta un panorama general de lo que aprenderemos.Imagina que los LLM (Modelos de Lenguaje Grande) son como genios de la lámpara maravillosa. Tú eres Aladino, y el \"prompt\" es tu deseo. Si formulas mal tu deseo, el genio te dará algo que no querías. La Ingeniería de Prompt es como aprender a hablar el idioma de los genios para que tus deseos se hagan realidad tal como los imaginas.En este curso, aprenderás las técnicas y trucos para comunicarte eficazmente con estos \"genios\" de la IA, para que puedas obtener respuestas precisas y útiles. No importa si eres programador o no, ¡todos podemos convertirnos en expertos en pedir deseos a la IA!¿Te gustaría que te diera otro ejemplo o analogía para entender mejor algún punto en específico?\n",
    "\n",
    "# 02 Preparando el ambiente\n",
    "Antes de comenzar…\n",
    "Durante el curso, utilizaremos diferentes herramientas de Inteligencia Artificial Generativa.\n",
    "\n",
    "En esta clase, utilizaremos ChatGPT, una herramienta disponible en la página de OpenAI. Para comenzar a usarla, es necesario crear una cuenta en OpenAI.\n",
    "\n",
    "Si aún no tienes una cuenta, simplemente haz clic en la opción \"Sign up\" o “Registrar” en la página de inicio y, a continuación, elige entre crear una cuenta o utilizar una cuenta de Google o Microsoft; si eliges la segunda opción, será necesario permitir que OpenAI acceda a tu información.\n",
    "\n",
    "Después de iniciar sesión, a continuación se presentan algunos pasos para comenzar a usar ChatGPT:\n",
    "\n",
    "1 - Escribe tu primer mensaje en el cuadro de texto y presiona \"Enviar\". Por ejemplo: puedes comenzar con un simple \"Hola\" o hacer una pregunta.\n",
    "\n",
    "2 - ChatGPT responderá automáticamente a tu mensaje con una respuesta generada por inteligencia artificial. A partir de ahí, puedes continuar la conversación haciendo más preguntas o respondiendo a las preguntas de ChatGPT.\n",
    "\n",
    "3 - Experimenta con diferentes tipos de preguntas o temas para ver de qué es capaz ChatGPT. Puedes preguntar sobre un tema específico, pedir ayuda con una tarea o simplemente conversar con ChatGPT.\n",
    "\n",
    "Si deseas cambiar de tema y comenzar una nueva conversación en cualquier momento, simplemente haz clic en la opción \"New chat\" (nueva conversación) en el menú lateral izquierdo.\n",
    "\n",
    "Para seguir este curso, puedes utilizar tanto la versión gratuita como la versión de pago, llamada \"Plus\".\n",
    "\n",
    "También utilizaremos el playground de OpenAI. Sin embargo, esta es una funcionalidad de pago. Para esta actividad, es posible utilizar el AI Studio, el playground del modelo Gemini de Google. Para utilizarlo, solo necesitas tener una cuenta de Gmail.\n",
    "\n",
    "Ahora que ya sabes cómo utilizar ChatGPT, ¡podemos comenzar!\n",
    "\n",
    "# 03 Proximidad Semántica\n",
    "¡Hola! En esta clase, Christian Velasco nos introduce a la Ingeniería de Prompt, una técnica clave para interactuar eficazmente con los LLMs (Large Language Models). Aquí tienes un resumen conciso de los puntos principales:\n",
    "¿Qué es la Ingeniería de Prompt? Es el arte de crear requisiciones claras y efectivas para obtener respuestas útiles de los modelos de lenguaje.\n",
    "* Modelos de Lenguaje (LLMs): Son algoritmos entrenados con grandes cantidades de datos para entender el lenguaje humano y resolver problemas.\n",
    "* Proximidad Semántica: Es una técnica que muestra cómo las palabras se relacionan entre sí en función de su uso común. Palabras que a menudo aparecen juntas tienen una alta proximidad semántica.\n",
    "* Word Embeddings: Representaciones matemáticas de palabras que capturan sus relaciones semánticas. Esto permite a los modelos entender analogías y predecir palabras en una oración.\n",
    "* Contexto en LLMs: Los LLMs tienen una \"memoria\" que les permite mantener el contexto de una conversación, lo que facilita interacciones más naturales.\n",
    "\n",
    "¿Te gustaría que profundizáramos en alguno de estos puntos o tienes alguna pregunta específica?\n",
    "\n",
    "#  04 Word embeddings\n",
    "Nathália es una desarrolladora que trabaja en una editorial de libros de tecnología. Ella está construyendo una solución basada en Inteligencia Artificial que haga sugerencias de nuevos libros para lectores que ya son clientes de la editorial.\n",
    "\n",
    "Para iniciar su proyecto, Nathália está aprendiendo sobre word embeddings y quedó impresionada por cómo las palabras son representadas y agrupadas en el espacio de embeddings.\n",
    "\n",
    "![prompt.png](/home/pol/Escritorio/ipynb-alura/assets/prompt.png)\n",
    "\n",
    "## En relación con la distribución de las palabras en este espacio, ¿cuáles afirmaciones son verdaderas?\n",
    "\n",
    "* Alternativa correta\n",
    "**Las palabras que comparten un significado muy cercano, como “calor” y “caliente”, están cerca en el espacio de embeddings.**\n",
    "\n",
    "\n",
    "Como \"calor\" y \"caliente\" se utilizan frecuentemente en contextos similares y tienen significados relacionados, sus embeddings terminan siendo similares, reflejando esta proximidad semántica.\n",
    "\n",
    "* Alternativa correta\n",
    "**Las palabras que pertenecen a la misma categoría gramatical, como sustantivos o verbos, están siempre cerca en el espacio de embeddings.**\n",
    "\n",
    "\n",
    "* Alternativa correta\n",
    "**Las palabras que suelen aparecer juntas en frases están más cerca en el espacio de embeddings.**\n",
    "\n",
    "\n",
    "Los modelos de lenguaje de gran tamaño son entrenados con base en una cantidad muy grande de texto y aprenden sobre la semántica de las palabras y sobre el contexto a partir de la coocurrencia de palabras en los textos de entrenamiento. Cuando las palabras se utilizan frecuentemente juntas, el modelo de embeddings \"aprende\" que tienen una relación contextual fuerte, resultando en `representaciones numérsicas (embeddings)` que están más cercanas entre sí.\n",
    "\n",
    "* Alternativa correta\n",
    "**Las palabras que tienen el opuesto de significado una de la otra están necesariamente muy distantes en el espacio de embeddings.**\n",
    "\n",
    "# 05 Temperatura y Tokens\n",
    "¡Hola! En esta clase, exploramos los conceptos de temperatura y tokens en la ingeniería de prompts. Aquí te presento algunas analogías para ayudarte a comprender mejor estos conceptos:\n",
    "Temperatura como un termostato para la creatividad:\n",
    "Imagina que la temperatura es como un termostato que controla la creatividad de un chef. Si ajustas el termostato a una temperatura baja (cercana a 0), el chef seguirá una receta al pie de la letra, siendo muy preciso y determinista en su cocina. Pero si subes la temperatura (cercana a 2), el chef se sentirá más libre para experimentar, añadir ingredientes inesperados y crear platos únicos, aunque a veces pueda resultar en algo no tan sabroso.\n",
    "\n",
    "\n",
    "Tokens como las piezas de un rompecabezas:\n",
    "Piensa en los tokens como las piezas de un rompecabezas. Cada palabra o parte de una palabra es una pieza. En algunos idiomas, como el inglés, las piezas son más grandes (una palabra puede ser una pieza), mientras que en otros, como el español, las piezas son más pequeñas (una palabra puede dividirse en varias piezas). Cuantas más piezas tenga un rompecabezas, más información necesita el modelo para entender la imagen completa.\n",
    "\n",
    "\n",
    "Tokens como el combustible de un coche:\n",
    "Considera los tokens como el combustible que necesita un coche para funcionar. Cada vez que envías un prompt a un modelo de lenguaje, estás gastando \"combustible\" (tokens). Algunos modelos son más eficientes y utilizan menos combustible por kilómetro recorrido (entienden mejor con menos tokens), mientras que otros necesitan más combustible para el mismo recorrido. Además, cada modelo tiene un límite de combustible que puede gastar, y si te pasas, tendrás que pagar más.\n",
    "\n",
    "\n",
    "\n",
    "Espero que estas analogías te ayuden a comprender mejor los conceptos de temperatura y tokens. ¿Te gustaría que profundizáramos en alguno de estos temas o tienes alguna otra pregunta?\n",
    "\n",
    "\n",
    "#  06 Hazlo como yo lo hice: explorando probabilidades\n",
    "En esta clase, descubrimos cómo los modelos de lenguaje de gran escala, como ChatGPT, comprenden y generan texto.\n",
    "\n",
    "Estos modelos son entrenados con una cantidad muy grande de textos y, durante el entrenamiento, van creando “comprensiones matemáticas” sobre lenguaje, semántica y significado.\n",
    "\n",
    "Cuando enviamos una instrucción al modelo, el texto se divide primero en tokens y luego se convierte en embeddings. Cada embedding es un valor numérico que representa la palabra en un espacio matemático, donde todo el vocabulario del modelo está organizado de acuerdo con el contexto.\n",
    "\n",
    "Entonces, el modelo genera una palabra a la vez, calculando cuál es la próxima palabra más probable en el contexto de la respuesta.\n",
    "\n",
    "También vimos el concepto de temperatura aplicado en la IA generativa: la temperatura es un parámetro que permite controlar si el modelo elegirá la palabra más probable y creará una respuesta robótica, o elegirá palabras con menor probabilidad y creará respuestas más creativas.\n",
    "\n",
    "¡Ahora es tu turno!\n",
    "Envía el prompt a continuación a ChatGPT y luego envía alguna frase incompleta para que él responda con las probabilidades. Experimenta con diversas frases para comprender mejor cómo se eligen las palabras en el momento de la generación de texto.\n",
    "\n",
    "Vamos a simular cómo funciona ChatGPT. Para cada frase que yo escriba en el prompt, debes listar las 5 palabras con mayor probabilidad que usarías para completarla, junto con la probabilidad de cada una de ellas. ¿De acuerdo? Solo las palabras y probabilidades, sin más nada. Dime si entendiste.\n",
    "Copia el código\n",
    "También puedes ajustar la temperatura en el playground del modelo para experimentar cómo funciona la generación de texto con diferentes valores de este parámetro.\n",
    "\n",
    "Consejo: OpenAI, la empresa que desarrolló ChatGPT, no ofrece un nivel gratuito de uso del playground. Para esta actividad, puedes utilizar el AI Studio, el playground del modelo Gemini, de Google. Para utilizarlo, solo necesitas tener una cuenta de Gmail. ¡Diviértete!\n",
    "\n",
    "Explora también el tokenizador de OpenAI.\n",
    "\n",
    "# Opinión del instructor\n",
    "\n",
    "Una experiencia divertida puede ser crear una frase con las palabras menos probables sugeridas por ChatGPT. Solo cambiando la palabra mayor por menor en el prompt que utilizamos en la simulación, así:\n",
    "\n",
    "Vamos a simular cómo funciona ChatGPT. Para cada frase que yo escriba en el prompt, debes listar las 5 palabras con menor probabilidad que usarías para completarla, junto con la probabilidad de cada una de ellas. ¿De acuerdo? Solo las palabras y probabilidades, sin más nada. Dime si entendiste.\n",
    "\n",
    "Al enviar la frase “Me gusta bucear en”, la mayor probabilidad de continuación sería “mar”, la segunda, “río”. Pero, pidiendo las menores probabilidades, tenemos como respuesta solo palabras que no tienen ninguna relación con el buceo:\n",
    "\n",
    "elefante - 0.00001%\n",
    "\n",
    "contenedor - 0.00002%\n",
    "\n",
    "camión - 0.00003%\n",
    "\n",
    "satélite - 0.00004%\n",
    "\n",
    "uranio - 0.00005%\n",
    "\n",
    "Comprender conceptos que explican cómo funcionan los modelos de lenguaje es un paso importante para aprender a sacar el mejor provecho de esta tecnología. En la próxima clase, conoceremos qué es la famosa Ingeniería de Prompt. ¡Vamos!\n",
    "\n",
    "#  07 ¿Qué aprendimos?\n",
    "En esta clase, aprendiste a:\n",
    "\n",
    "* Conceptualizar cómo las palabras son representadas en el modelo a través de word embeddings y tokens;\n",
    "* Identificar cómo las palabras se relacionan a través de la semántica en un modelo de lenguaje;\n",
    "* Simular el funcionamiento del modelo de lenguaje visualizando probabilidades;\n",
    "* Explorar el parámetro de temperatura en el playground de OpenAI.\n",
    "\n",
    "----------\n",
    "# 2 - Ing. de Prompts\n",
    "\n",
    "# 01 ¿Qué es Ingeniería de Prompt?\n",
    "\n",
    "¡Hola! En esta clase, exploramos la importancia de la Ingeniería de Prompt y cómo crear prompts efectivos para obtener resultados más asertivos de los modelos de lenguaje como Gemini.Aquí tienes un resumen de los puntos clave:\n",
    "* Ingeniería de Prompt: No es una ciencia exacta, pero se basa en buenas prácticas y fundamentos para extraer valor de los LLMs.\n",
    "* Caso Práctico: Se utilizó el ejemplo de crear un post para Instagram sobre inteligencia artificial para demostrar la diferencia entre un prompt genérico y uno específico.\n",
    "* Prompt Genérico vs. Prompt Mejorado: Un prompt genérico produce respuestas genéricas, mientras que un prompt con más contexto y detalles genera resultados más adecuados y asertivos.\n",
    "* Ejemplo de Prompt Mejorado: Se proporcionó un prompt detallado que especificaba el formato, el lenguaje y el público objetivo del post de Instagram, lo que resultó en un texto más atractivo y relevante.\n",
    "* Importancia de las Buenas Prácticas: Existen técnicas que se pueden implementar para asegurar que los resultados sean repetibles y que atiendan las necesidades del usuario.\n",
    "\n",
    "En resumen, la clave para obtener buenos resultados de los LLMs es proporcionar prompts específicos y bien definidos que tengan en cuenta el contexto, el público objetivo y el formato deseado.¿Te gustaría que profundizáramos en algún aspecto en particular?\n",
    "\n",
    "#  02 Para saber más: motivando la acción\n",
    "Contenido: El término prompt es conocido desde hace tiempo por personas que trabajan en el área de tecnología. El “Símbolo del sistema” de Windows, por ejemplo, es una interfaz que recibe códigos que ejecutan funciones administrativas avanzadas en el sistema operativo. En el área de la computación, este término se ha utilizado desde las primeras interacciones de usuarios con máquinas a través de texto.\n",
    "\n",
    "Pero… ¿qué significa esta palabra?\n",
    "\n",
    "En traducción literal del inglés, prompt significa “incitar” o “inducir”, “hacer que algo suceda”, “motivar”. Es un verbo que indica que algún movimiento está a punto de suceder.\n",
    "\n",
    "Cuando una interfaz presenta un prompt para la persona usuaria, es exactamente eso lo que está sucediendo: el programa nos está “provocando” a hacer una solicitud a través de la línea de comandos. Cuando enviamos el comando, devolvemos el incentivo, y esto inicia la interacción entre la persona y la máquina.\n",
    "\n",
    "En el contexto de modelos de lenguaje e inteligencia artificial, el prompt es fundamental y permite que la interacción se asemeje a una conversación, con el uso de lenguaje natural.\n",
    "\n",
    "Por lo tanto, crear un buen prompt para interactuar con un modelo de lenguaje requiere técnicas que comprendan el funcionamiento de esta tecnología, así como en la comunicación humana: es importante conocer al público objetivo para adaptar el discurso en una charla, por ejemplo. De la misma manera, es importante conocer los fundamentos de un modelo de lenguaje para adaptar la comunicación y obtener buenos resultados.\n",
    "\n",
    "#  03 Preparando el ambiente\n",
    "En la siguiente clase, utilizaremos el modelo de lenguaje Gemini de Google. Puedes usar cualquier modelo que prefieras para seguir la clase, pero, si deseas conocer Gemini, es necesario acceder a la plataforma.\n",
    "\n",
    "Para comenzar, solo necesitas una cuenta de Google. Inicia sesión con tu cuenta existente o, si aún no tienes una, puedes crear una nueva de forma gratuita.\n",
    "\n",
    "# 04 Principios y Frameworks\n",
    "¡Hola! En esta clase, aprendimos sobre los principios para diseñar un prompt ideal y cómo los frameworks pueden ayudarnos a estructurarlos de manera efectiva.Aquí tienes un resumen de los puntos clave:\n",
    "## Principios para un Prompt Ideal:\n",
    "* Claridad en las instrucciones: Ser lo más claro y específico posible al escribir el prompt.\n",
    "* Dividir tareas complejas: Descomponer problemas grandes en subtareas más pequeñas para obtener resultados más precisos.\n",
    "* Explicaciones paso a paso: Pedir al LLM que explique el proceso antes de dar la respuesta, especialmente en ejercicios de lógica.\n",
    "* Justificaciones para las respuestas: Solicitar que se justifiquen las respuestas, sobre todo al trabajar con información basada en hechos.\n",
    "* Generación de múltiples respuestas: Generar varias respuestas diferentes y elegir la mejor opción, útil para generar ideas.\n",
    "\n",
    "\n",
    "## Frameworks para Generar Prompts:\n",
    "* Clear: Contexto, Longitud, Expectativa, Acción y Resultado.\n",
    "* Smart: Específico, Medible, Alcanzable, Relevante y con un horizonte de Tiempo definido.\n",
    "* Ideal y Brief: Otros frameworks que se pueden aplicar a diferentes situaciones.\n",
    "\n",
    "\n",
    "## Ejemplo Práctico con Clear:\n",
    "Se desarrolló un prompt utilizando el framework Clear para generar ideas de campañas de marketing para una aplicación de comida a domicilio.\n",
    "Se probó el prompt en ChatGPT, obteniendo cinco ideas concretas que podrían aumentar las descargas de la aplicación.\n",
    "\n",
    "\n",
    "\n",
    "¿Te gustaría que profundicemos en alguno de estos puntos o tienes alguna pregunta específica?\n",
    "\n",
    "#  05 Comunicando instrucciones\n",
    "María Isabel, una ingeniera de datos senior, necesita orientar a un pasante que acaba de llegar a la empresa. Ella sabe que, para hacerse entender, es necesario tomar algunas precauciones en la forma en que comunica las tareas, especialmente las más complejas.\n",
    "\n",
    "Estas mismas precauciones son recomendadas al escribir comandos para una IA generativa.\n",
    "\n",
    "¿Cuáles de los siguientes elementos son importantes tanto en la comunicación con el pasante como en la creación de prompts para una IA generativa?\n",
    "\n",
    "Usar términos técnicos complejos para garantizar precisión en la comunicación.\n",
    "\n",
    "\n",
    "* Alternativa incorreta\n",
    "Incluir detalles personales en la explicación, creando una relación amigable para que el pasante se sienta a gusto.\n",
    "\n",
    "\n",
    "* Alternativa correcta\n",
    "Hablar las instrucciones con claridad, dividir tareas complejas en subtareas más pequeñas y explicar el razonamiento detrás de las instrucciones.\n",
    "\n",
    "Estos elementos son fundamentales para evitar malentendidos en la comunicación y mejorar la precisión y, por lo tanto, obtener resultados más asertivos. Claridad, explicación y división de tareas complejas en tareas más pequeñas funcionan bien tanto al enseñar a una persona aprendiz como al dar instrucciones a la IA.\n",
    "\n",
    "Alternativa incorreta\n",
    "Permitir flexibilidad en las respuestas, dejando espacio para la interpretación.\n",
    "\n",
    "\n",
    "#  06 Haz como yo hice: principios fundamentales\n",
    "En esta clase, vimos algunos principios generales de la Ingeniería de Prompt: el acto de construir cuidadosamente un comando eficaz para extraer el mejor resultado posible de una IA generativa.\n",
    "\n",
    "Estas directrices han demostrado ser efectivas para mejorar la calidad de las respuestas. Las principales son:\n",
    "\n",
    "* Tener claridad al dar las instrucciones;\n",
    "* Dividir tareas complejas en subtareas más pequeñas;\n",
    "* Pedir al modelo que explique sus pasos antes de dar la respuesta;\n",
    "* Pedir al modelo que justifique sus respuestas;\n",
    "* Generar varias respuestas diferentes y pedir al modelo que elija la mejor.\n",
    "\n",
    "\n",
    "## Practica tú también!\n",
    "El siguiente prompt contiene las pistas del juego de detective y las alternativas “Sí”, “No” y “Desconocido”.\n",
    "\n",
    "Usa las siguientes pistas para responder a la siguiente pregunta de opción múltiple.\n",
    "\n",
    "Pistas:\n",
    "1. La Señorita Scarlett era la única persona en la sala.\n",
    "2. La persona con la pipa estaba en la cocina.\n",
    "3. El Coronel Mostaza era la única persona en el observatorio.\n",
    "4. El Profesor Ciruela no estaba en la biblioteca ni en la sala de billar.\n",
    "5. La persona con el candelabro estaba en el observatorio.\n",
    "\n",
    "Pregunta: ¿El Coronel Mostaza estaba en el observatorio con el candelabro? \n",
    "(a) Sí; El Coronel Mostaza estaba en el observatorio con el candelabro\n",
    "(b) No; El Coronel Mostaza no estaba en el observatorio con el candelabro\n",
    "(c) Desconocido, no hay suficiente información para determinar si el Coronel Mostaza estaba en el observatorio con el candelabro\n",
    "\n",
    "Respuesta:______________\n",
    "\n",
    "* Prueba también, en otro chat, el mismo juego, pero aplicando algunos principios de la ingeniería de prompt.\n",
    "\n",
    "Usa las siguientes pistas para responder a la siguiente pregunta de opción múltiple, utilizando el siguiente procedimiento:\n",
    "\n",
    "(1) Primero, analiza las pistas una por una y considera si la pista es potencialmente relevante\n",
    "(2) En segundo lugar, combina las pistas relevantes para razonar la respuesta correcta a la pregunta\n",
    "(3) En tercer lugar, mapea la respuesta a una de las respuestas de opción múltiple: (a), (b) o (c)\n",
    "\n",
    "Pistas:\n",
    "1. La Señorita Scarlett era la única persona en la sala.\n",
    "2. La persona con la pipa estaba en la cocina.\n",
    "3. El Coronel Mostaza era la única persona en el observatorio.\n",
    "4. El Profesor Ciruela no estaba en la biblioteca ni en la sala de billar.\n",
    "5. La persona con el candelabro estaba en el observatorio.\n",
    "\n",
    "Pregunta: ¿El Coronel Mostaza estaba en el observatorio con el candelabro? \n",
    "(a) Sí; El Coronel Mostaza estaba en el observatorio con el candelabro\n",
    "(b) No; El Coronel Mostaza no estaba en el observatorio con el candelabro\n",
    "(c) Desconocido, no hay suficiente información para determinar si el Coronel Mostaza estaba en el observatorio con el candelabro\n",
    "\n",
    "Respuesta:______________\n",
    "\n",
    "En este último prompt, dividimos la tarea principal en subtareas, y la instrucción se volvió más clara, en consecuencia. Compara los resultados y prueba en diferentes modelos. También es interesante probar en tareas de tu día a día que no obtuvieron resultados satisfactorios anteriormente.\n",
    "\n",
    "\n",
    "# Opinión del instructor\n",
    "\n",
    "En el momento en que estás haciendo este curso, puede ser que los modelos de lenguaje actuales ya estén mucho más preparados para responder al enigma del Coronel Mostaza, incluso sin las especificidades de las orientaciones del segundo prompt. ¡Eso es genial!\n",
    "\n",
    "El área de IA se mueve con mucha rapidez y los modelos están en constante mejora. El ChatGPT 4, por ejemplo, que fue lanzado en 2024, tiene alrededor de 170 billones de parámetros en su entrenamiento, y ya ha sido perfeccionado por las experimentaciones científicas realizadas con los modelos que vinieron antes de él.\n",
    "\n",
    "Como comparación, el modelo 3.5 (el que fue lanzado en 2022 y trajo el tema de IA a la luz), tenía 170 mil millones de parámetros. ¡Es decir, el modelo 4 tiene un “conocimiento” mil veces mayor que su modelo anterior! Este salto impresionante impacta considerablemente en la capacidad del modelo.\n",
    "\n",
    "Sin embargo, la mejora en la capacidad de los modelos no nos exime de conocer las técnicas de ingeniería de prompt, ¡todo lo contrario! A medida que la tecnología avanza en complejidad, es imperativo que nosotros, las personas que usamos estas tecnologías, avancemos en nuestra comprensión sobre ellas también.\n",
    "\n",
    "#  07 ¿Qué aprendimos?\n",
    "En esta clase, aprendiste:\n",
    "\n",
    "* Lo que significa el término “Ingeniería de Prompt”;\n",
    "* Las principales recomendaciones para crear un prompt eficaz.\n",
    "\n",
    "----------\n",
    "\n",
    "# 3 - Few-shot y chain-of-Thought Prompt\n",
    "## 01 Preparando el ambiente\n",
    "En la siguiente clase, utilizaremos el modelo de lenguaje DeepSeek. Puedes usar cualquier modelo que prefieras para seguir la clase, pero, si deseas conocer DeepSeek, es necesario acceder a la plataforma.\n",
    "\n",
    "Para comenzar, puedes iniciar sesión con tu cuenta de Google o Microsoft. Si aún no tienes una cuenta, puedes registrarte fácilmente en la plataforma.\n",
    "\n",
    "## 02 Zero-Shot vs Few-Shot\n",
    "¡Hola! Soy Luri, tu asistente de IA de Alura. ¡Claro que sí! Aquí tienes una explicación de la clase usando analogías para que sea más fácil de entender:\n",
    "\n",
    "### Analogía 1: Zero-Shot Prompt como un Chef Experto\n",
    "**Situación: Imagina que tienes un chef experto en cocina internacional.**\n",
    "### Zero-Shot Prompt:\n",
    "Le dices al chef: **\"Prepara un plato delicioso con ingredientes locales.\"** No le das ninguna receta, ni le dices qué tipo de plato quieres. Confías en su experiencia y conocimiento para crear algo bueno.\n",
    "En la clase: Zero-Shot Prompt es como hacer una pregunta directa a un modelo de lenguaje sin darle ejemplos. Esperas que el modelo, con todo lo que ha aprendido, te dé una buena respuesta.\n",
    "\n",
    "### Analogía 2: Few-Shot Prompt como Enseñar a un Aprendiz\n",
    "**Situación: Ahora tienes un aprendiz de cocina que necesita aprender a hacer ciertos platos.**\n",
    "### Few-Shot Prompt:\n",
    " Le muestras al aprendiz algunos ejemplos de cómo hacer un plato específico. Le dices: **\"Así se hace una paella (ejemplo 1), así se hace un risotto (ejemplo 2).\" Luego le pides que prepare un plato similar, como un arroz caldoso.**\n",
    "En la clase: Few-Shot Prompt es como darle al modelo de lenguaje algunos ejemplos de lo que quieres. Le muestras cómo responder en ciertos casos y luego le pides que aplique ese mismo patrón a nuevas preguntas.\n",
    "\n",
    "### Analogía 3: Deep Think como un Detective Resolviendo un Caso\n",
    "**Situación: Un detective está resolviendo un caso complicado.**\n",
    "#### Deep Think: El detective no solo busca la respuesta rápida, sino que analiza cada pista, revisa los hechos y considera todas las posibilidades antes de llegar a una conclusión.\n",
    "En la clase: Deep Think es como pedirle al modelo de lenguaje que haga un análisis profundo y detallado antes de responder. Es útil para problemas complejos donde necesitas un razonamiento más elaborado.\n",
    "\n",
    "Espero que estas analogías te ayuden a entender mejor los conceptos de Zero-Shot, Few-Shot y Deep Think. ¿Hay algo más en lo que te pueda ayudar?\n",
    "\n",
    "#  03 Para saber más: Few-Shot vs Zero-Shot\n",
    "En 2020, científicos de OpenAI publicaron un artículo llamado Language Models are Few-Shot Learners, es decir: los modelos de lenguaje aprenden con algunos ejemplos.\n",
    "\n",
    "Este artículo describe las técnicas de aprendizaje automático utilizadas en el entrenamiento del modelo de lenguaje de gran tamaño GPT-3. El artículo informa cómo se observó que el modelo, ya entrenado en una gran cantidad de texto, puede demostrar mejores resultados en tareas específicas después de pasar por un “refinamiento” en el entrenamiento, enfocado en esas tareas.\n",
    "\n",
    "Desde entonces, el GPT ha evolucionado y ha tenido un rendimiento cada vez mejor en una diversidad de tareas, y la técnica de few-shot learning se ha expandido a los prompts enviados por personas usuarias de ChatGPT y de otros modelos de lenguaje en general.\n",
    "\n",
    "Con esta técnica, utilizamos, de manera indirecta, algunos de los pilares del aprendizaje automático que se emplearon en el entrenamiento de estos LLMs. Como:\n",
    "\n",
    "Aprendizaje por ejemplos. El modelo, inicialmente, aprende a reconocer patrones y estructuras a partir de una gran cantidad de ejemplos. Cuando el prompt contiene ejemplos, el modelo utiliza ese aprendizaje anterior para inferir patrones y lógica necesarias.\n",
    "Memorización y Generalización: La técnica de few-shot prompting se basa en la capacidad que tiene el modelo de memorizar patrones y, luego, generalizar esos patrones a otras situaciones.\n",
    "Predicción secuencial: Los modelos son entrenados para predecir la siguiente palabra de una secuencia. Los ejemplos en el prompt ayudan al modelo a predecir de manera más precisa en tareas específicas.\n",
    "Esto nos lleva a considerar que, incluso con incontables beneficios en la utilización de few-shot prompting en la precisión de la respuesta del modelo, puede que no sea la técnica más adecuada para todas las situaciones. Además, es notable que los comandos con zero-shot son mejor “comprendidos” en modelos más avanzados, como el GPT-4, debido a su entrenamiento más amplio.\n",
    "\n",
    "Comprender estas diferencias es crucial para decidir cómo y cuándo aplicar las técnicas de few-shot prompting y zero-shot prompting de manera eficaz. A continuación, observa en qué situaciones cada enfoque es más adecuado.\n",
    "\n",
    "Cuándo utilizar Few-Shot Prompting\n",
    "Cuando la tarea requiere alta precisión;\n",
    "Generación de textos con un formato definido;\n",
    "En categorizaciones donde hay mucha variedad;\n",
    "Tareas con reglas complejas.\n",
    "Cuándo utilizar Zero-Shot Prompting\n",
    "Exploración inicial de nuevas tareas, que aún no disponen de ejemplos;\n",
    "Cuando quieres que el modelo generalice;\n",
    "En tareas simples y bien definidas, como la categorización de spams obvios, por ejemplo;\n",
    "Situaciones que exigen respuestas rápidas en detrimento de precisión;\n",
    "Cuando proporcionar ejemplos específicos puede introducir sesgo no deseado.\n",
    "Elegir la técnica apropiada puede mejorar significativamente la calidad de las respuestas generadas y la eficiencia en la realización de diversas tareas. Mientras que el few-shot prompting permite un ajuste más fino y preciso al proporcionar ejemplos específicos, el zero-shot prompting es valioso para tareas generales y cuando se necesita flexibilidad.\n",
    "\n",
    "\n",
    "# 04 Chain-of-Though\n",
    "¡Hola! En esta clase, exploramos la técnica \"Chain of Thought\" (cadena de pensamientos) para mejorar la precisión de las respuestas de los modelos de lenguaje.Imagina que estás enseñando a un niño a resolver un problema matemático. En lugar de simplemente darle la respuesta, le explicas paso a paso cómo llegar a ella. Por ejemplo:Problema: María tiene 5 caramelos y Juan le da 3 más. ¿Cuántos caramelos tiene María en total?Explicación paso a paso (Chain of Thought):\n",
    "María empieza con 5 caramelos.\n",
    "Juan le da 3 caramelos más.\n",
    "Para saber el total, sumamos los caramelos iniciales (5) con los que le dio Juan (3).\n",
    "5 + 3 = 8\n",
    "Por lo tanto, María tiene 8 caramelos en total.\n",
    "\n",
    "La técnica \"Chain of Thought\" es similar. Le proporcionamos al modelo de lenguaje una serie de \"pensamientos\" o pasos lógicos que lo guían hacia la respuesta correcta. Esto ayuda al modelo a comprender el problema y a generar una respuesta más precisa y coherente.¿Te gustaría que te diera otro ejemplo o tienes alguna pregunta sobre esta analogía?\n",
    "\n",
    "#  05 Para saber más: Zero-Shot con Chain of Thought\n",
    "Contenido: La técnica Chain of Thought nació con base en el few-shot prompting. Es decir, la cadena de pensamientos se presentaba al modelo en la respuesta de cada ejemplo proporcionado, y, al basarse en los ejemplos, el modelo replicaba la lógica necesaria para la solución de problemas más simbólicos.\n",
    "\n",
    "Sin embargo, un estudio posterior exploró la capacidad de los modelos para explicar razonamientos incluso sin una cantidad elaborada de ejemplos, solo con la adición de la frase “explique paso a paso” en el prompt.\n",
    "\n",
    "Esta técnica es particularmente útil en situaciones que requieren pensamiento simbólico y abstracto, como decisiones estratégicas, problemas matemáticos complejos, análisis filosófico y ético o interpretación de datos científicos, por ejemplo.\n",
    "\n",
    "Como vimos en la clase sobre few-shot y zero-shot prompting, los modelos avanzados pueden manejar mucho mejor los comandos sin orientación explícita. Aun así, el uso del comando “explique paso a paso” sigue siendo extremadamente útil en escenarios donde el detalle cuidadoso y la consideración de múltiples factores son cruciales.\n",
    "\n",
    "#  06 Eligiendo técnicas\n",
    "Harri está planeando abrir su panadería y, como quiere tener tiempo para desarrollar recetas y crear relaciones saludables con su equipo, se está dedicando a automatizar algunos procesos simples, pero que consumen bastante tiempo en el día a día. Está explorando cómo usar modelos de lenguaje para ayudar a categorizar los correos electrónicos que recibe como “pedidos”, “comentarios”, “proveedores”, “promociones” y “general”.\n",
    "\n",
    "¿Cuál enfoque es más apropiado para hacer la categorización automática de los correos electrónicos?\n",
    "\n",
    "**Utilizar few-shot prompting y proporcionar ejemplos específicos para cada una de las categorías deseadas.**\n",
    "* Proporcionar ejemplos específicos para cada categoría ayuda al modelo a entender mejor las características de cada tipo de correo electrónico, aumentando la precisión de la categorización.\n",
    "\n",
    "Utilizar zero-shot prompting y solo proporcionar al modelo una instrucción como “categoriza los comentarios en categorías”.\n",
    "\n",
    "\n",
    "Instrucciones vagas pueden llevar a una categorización inconsistente. Incluso si el modelo reconoce patrones, pueden ser muy diferentes de lo que se desea.\n",
    "\n",
    "Alternativa incorreta\n",
    "Proporcionar ejemplos de correos electrónicos que no encajan claramente en ninguna de las categorías y pedir al modelo que los clasifique en las categorías existentes.\n",
    "\n",
    "\n",
    "Ejemplos ambiguos sin una definición clara pueden confundir al modelo y resultar en una categorización imprecisa o inadecuada.\n",
    "\n",
    "Alternativa incorreta\n",
    "Proporcionar ejemplos para solo una de las categorías, y dejar que el modelo decida sobre el resto.\n",
    "\n",
    "\n",
    "Proporcionar ejemplos para solo una de las categorías puede introducir sesgo en el modelo y hacer que la categorización sea menos precisa.\n",
    "\n",
    "¡Enhorabuena, has acertado!\n",
    "\n",
    "#  07 Hazlo como yo lo hice: comandos con ejemplos\n",
    "En esta clase, conocimos los conceptos de zero-shot, one-shot y few-shot prompting.\n",
    "\n",
    "Zero-shot prompting: solo el comando, sin ningún ejemplo;\n",
    "One-shot prompting: cuando hay un ejemplo del comportamiento esperado del modelo, además del comando;\n",
    "Few-shot prompting: cuando hay dos o más ejemplos del comportamiento esperado del modelo, además del comando.\n",
    "Enviar uno o más ejemplos orienta al modelo sobre cómo generar la respuesta, y es mucho más eficaz que una descripción detallada del formato. Además, los ejemplos también indican con qué área de conocimiento estamos trabajando, ya sea matemáticas, traducción, análisis de sentimientos, etc.\n",
    "\n",
    "¡Ahora es tu turno!\n",
    "Observa, en tu día a día de trabajo o estudios, alguna situación que exige un patrón y se beneficiaría del uso de la Inteligencia Artificial.\n",
    "\n",
    "Si lo prefieres, también puedes probar con los mismos ejemplos que se trabajaron en clase.\n",
    "\n",
    "Problema de matemáticas\n",
    "\n",
    "Pregunta: Juan tiene 10 pelotas. La mitad de ellas son azules y la mitad son rojas. ¿Cuántas pelotas rojas tiene Juan?\n",
    "\n",
    "Respuesta: La respuesta es 5.\n",
    "\n",
    "Pregunta: Un director de cine ya ha dirigido 16 películas. La mitad de las películas que ha dirigido son de acción, y la mitad de las películas de acción tienen la participación de Nicolas Cage, y en la mitad de ellas, Nicolas Cage tiene bigote. ¿Cuántas películas de acción con la participación de Nicolas Cage con bigote ha dirigido?\n",
    "\n",
    "Respuesta:_______________\n",
    "\n",
    "Otro problema de matemáticas\n",
    "\n",
    "Pregunta: Roger tiene 5 pelotas de tenis. Compra 2 latas más de pelotas de tenis. Cada lata contiene 3 pelotas de tenis. ¿Cuántas pelotas de tenis tiene ahora?\n",
    "\n",
    "Respuesta: La respuesta es 11.\n",
    "\n",
    "Pregunta: Había 23 manzanas en la cafetería. Si se usaron 20 para hacer el almuerzo y se compraron 6 más, ¿cuántas manzanas tienen ahora?\n",
    "\n",
    "Respuesta:\n",
    "Copia el código\n",
    "Análisis de sentimientos\n",
    "\n",
    "\"Esta película fue terrible\" \n",
    "- Negativo\n",
    "\n",
    "\"¡Esta película es mi película favorita ahora!\" \n",
    "- Positivo\n",
    "\n",
    "\"¡Esta es la peor película que he visto!\"\n",
    "- Negativo\n",
    "\n",
    "\"Esta película fue buena\"\n",
    "-\n",
    "Copia el código\n",
    "Traducción\n",
    "\n",
    "Inglés: Hello, how are you? \n",
    "Francés: Bonjour, comment ça va?\n",
    "\n",
    "Inglés: I am learning to speak French. \n",
    "Francés: J'apprends à parler français.\n",
    "\n",
    "Inglés: The weather is very nice today.\n",
    "\n",
    "# Opinión del instructor\n",
    "\n",
    "Una de las ventajas más interesantes de la técnica few-shot prompting es la posibilidad de mantener un estilo.\n",
    "\n",
    "Si te gusta escribir textos para un blog, por ejemplo, pero tienes dificultad para elegir títulos, puedes mostrar al modelo algunos textos que ya has escrito con los títulos que más te gustaron. El modelo entenderá el patrón y dará sugerencias que sigan tu estilo.\n",
    "\n",
    "Otra aplicación interesante es la reescritura de textos en diferentes estilos, para comunicar el mismo tema a diversos públicos. Simplemente instruir al modelo para que reescriba un texto con un lenguaje informal, generalmente, no tiene resultados tan naturales. Sin embargo, con ejemplos de calidad, esta tarea puede tener una gran asistencia.\n",
    "\n",
    "#  08 ¿Qué aprendimos?\n",
    "En esta clase, aprendiste a:\n",
    "\n",
    "* Conceptualizar el zero-shot y el few-shot prompting;\n",
    "* Aplicar la técnica de few-shot prompting en diferentes contextos.\n",
    "* Utilizar técnicas few-shot y zero-shot con chain of thought.\n",
    "\n",
    "-----------\n",
    "\n",
    "# 4 - Más técnicas\n",
    " ## 01 - Least-to-Most Prompting\n",
    "\n",
    " \n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
