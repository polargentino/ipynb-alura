{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5aa0c7d",
   "metadata": {},
   "source": [
    "## 01 Analisis de evasion de clientes\n",
    "¡Hola! ¡Qué bueno tenerte aquí para profundizar en este tema!\n",
    "\n",
    "Claro, puedo ayudarte con analogías para entender mejor el rol del científico de datos en este contexto:\n",
    "\n",
    "Imagina que eres un **detective**, pero en lugar de resolver crímenes, resuelves **problemas de negocios**.\n",
    "\n",
    "### Análisis Exploratorio (Primera Parte del Challenge):\n",
    "\n",
    "Sería como la **investigación inicial** del detective. Recopilas todas las **pistas** (datos), examinas la **escena del crimen** (situación actual de la empresa), y tratas de entender **qué ha estado pasando** hasta ahora.\n",
    "\n",
    "### Construcción de Modelos Predictivos (Segunda Parte del Challenge):\n",
    "\n",
    "Aquí, te conviertes en un **analista de perfiles criminales**. Usas la información que recopilaste para **predecir** quiénes son los clientes que están a punto de \"escapar\" (evadirse). Es como crear un **perfil** de los clientes en riesgo basándote en su comportamiento pasado.\n",
    "\n",
    "### Herramientas y Técnicas:\n",
    "\n",
    "* **Python, Pandas, SQL, Matplotlib:** Son tus **herramientas forenses**.\n",
    "    * **Python:** Es tu **kit de herramientas** general.\n",
    "    * **Pandas:** Te ayuda a **organizar las pruebas** (datos).\n",
    "    * **SQL:** Te permite **interrogar a la base de datos** como si fuera un testigo.\n",
    "    * **Matplotlib:** Te ayuda a **visualizar la evidencia** para presentarla de manera clara.\n",
    "\n",
    "### Entrega Final:\n",
    "\n",
    "Tu **informe final** es el **notebook** que entregas. Debe incluir un **análisis claro** (tu versión de los hechos), un **modelo evaluado** (la solidez de tu caso) y una **conclusión estratégica** (tus recomendaciones para evitar futuros \"crímenes\").\n",
    "\n",
    "¿Te gustaría que profundicemos en alguna de estas analogías o en algún otro aspecto del tema?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4cf736",
   "metadata": {},
   "source": [
    "##  02 Trello del Desafio\n",
    "### Trello del Desafío\n",
    "Trello es una herramienta de colaboración y gestión de proyectos que permite organizar tareas en tarjetas. Usarás esta herramienta para gestionar el desarrollo de tu proyecto.\n",
    "\n",
    "Accede al tablero del desafío\n",
    "Inicia sesión en tu cuenta de Trello y accede al tablero del desafío mediante el siguiente enlace:\n",
    "\n",
    "Challenge ONE Data Science – Telecom X parte 2(https://trello.com/b/y1FQQnc7/telecomxparte2latam)\n",
    "\n",
    "### Creando tu copia de Trello\n",
    "Para comenzar a gestionar tu progreso, sigue estos pasos:\n",
    "\n",
    "Accede al tablero del desafío: Challenge ONE Data Science: Telecom X parte 2\n",
    "\n",
    "Crea un tablero a partir de este modelo:\n",
    "\n",
    "En la parte superior del tablero, haz clic en 'Crear tablero basado en plantilla' o, si lo prefieres, en los tres puntos en la parte superior y selecciona 'Copiar tablero'.\n",
    "\n",
    "Ahora tienes una copia del tablero, incluyendo listas, tarjetas y etiquetas. Utiliza esta estructura para aplicar la metodología ágil y seguir tu progreso moviendo las tarjetas a medida que avanzas en el desafío."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef1ea6b",
   "metadata": {},
   "source": [
    "##  03 Preparando el ambiente\n",
    "### Creación de modelos predictivos\n",
    "Después de completar la etapa de ETL (Extract, Transform, Load) en la Parte 1 del desafío, es momento de utilizar los datos ya tratados para avanzar en la construcción de modelos predictivos.\n",
    "\n",
    "Para ello, asegúrate de estar utilizando el conjunto de datos que ya limpiaste y transformaste anteriormente. Esta continuidad es fundamental para garantizar la consistencia de los análisis y la eficacia de los modelos.\n",
    "\n",
    "En caso de que aún no hayas extraído los datos tratados de la Parte 1, puedes guardarlos en un archivo CSV con el siguiente comando:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf83a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.to_csv(\"datos_tratados.csv\", index=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea549876",
   "metadata": {},
   "source": [
    "Con este archivo, podrás cargar los datos ya listos para análisis y modelado en esta segunda parte del desafío."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c6ddee",
   "metadata": {},
   "source": [
    "##  04 Para saber más\n",
    "Este desafío fue diseñado para que puedas aplicar de manera práctica los conocimientos adquiridos en los siguientes cursos:\n",
    "\n",
    "* Curso Online Estadística con Python: frecuencias y medidas | Alura\n",
    "\n",
    "* Curso Online Estadística con Python: Probabilidad y muestreo | Alura\n",
    "\n",
    "* Curso Online Data Science: probando relaciones con regresión lineal | Alura\n",
    "\n",
    "* Curso Online Regresión Lineal: Técnicas Avanzadas de Modelado | Alura\n",
    "\n",
    "* Curso Online Clasificación: aprendiendo a clasificar datos con Machine Learning | Alura\n",
    "\n",
    "* Curso Online Clasificación: validación de modelos y métricas de evaluación | Alura\n",
    "\n",
    "* Curso Online IA aumentada: previsión de atrasos de vuelos | Alura"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbcbd03",
   "metadata": {},
   "source": [
    "#  01 Suba su proyecto en GitHub\n",
    "Git y GitHub\n",
    "Git y GitHub son herramientas esenciales para cualquier analista de datos, ya que permiten el versionado y el intercambio eficiente de proyectos.\n",
    "\n",
    "En este desafío, deberás subir tu cuaderno de Colab a un repositorio en GitHub. Esto garantizará que tu progreso esté guardado y accesible desde cualquier lugar.\n",
    "\n",
    "Lo que necesitas hacer:\n",
    "Crea un nuevo repositorio en GitHub para almacenar tu proyecto.\n",
    "\n",
    "Exporta tu cuaderno de Colab como un archivo .ipynb.\n",
    "\n",
    "Realiza el upload del cuaderno al repositorio.\n",
    "\n",
    "Mantén tu trabajo actualizado utilizando git pull, git add, git commit y git push cuando sea necesario.\n",
    "\n",
    "Si necesitas repasar conceptos, revisa los siguientes recursos:\n",
    "\n",
    "Git - Configurando Git por primera vez\n",
    "\n",
    "Cómo subir mi proyecto en GitHub\n",
    "\n",
    "Cómo escribir un README increíble en tu Github\n",
    "\n",
    "README\n",
    "El archivo README es esencial para documentar tu proyecto, explicando su propósito, funcionalidades e instrucciones de uso.\n",
    "\n",
    "Como desafío adicional, crea un archivo README.md para tu proyecto Telecom X - Parte 2, incluyendo:\n",
    "\n",
    "El propósito del análisis realizado, destacando el objetivo principal: predecir el churn (cancelación) de clientes en base a variables relevantes.\n",
    "\n",
    "Estructura del proyecto y organización de los archivos, como el cuaderno principal, los datos tratados en formato CSV y cualquier carpeta con visualizaciones.\n",
    "\n",
    "Descripción del proceso de preparación de los datos, incluyendo:\n",
    "\n",
    "Clasificación de las variables en categóricas y numéricas.\n",
    "\n",
    "Etapas de normalización o codificación.\n",
    "\n",
    "Separación de los datos en conjuntos de entrenamiento y prueba.\n",
    "\n",
    "Justificaciones para las decisiones tomadas durante la modelización.\n",
    "\n",
    "Ejemplos de gráficos e insights obtenidos durante el análisis exploratorio de datos (EDA).\n",
    "\n",
    "Instrucciones para ejecutar el cuaderno, incluyendo qué bibliotecas deben instalarse y cómo cargar los datos tratados.\n",
    "\n",
    "Este README hará que tu proyecto sea más completo, organizado y fácil de entender, lo cual es un gran diferencial tanto en entornos académicos como profesionales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52096c3e",
   "metadata": {},
   "source": [
    "##  02 Entrega del Challenge\n",
    "¡Felicidades por completar tu challenge! Estamos seguros de que desarrollaste un proyecto increíble.\n",
    "\n",
    "¡IMPORTANTE!\n",
    "Verifica la URL de tu proyecto antes de enviarlo.\n",
    "\n",
    "El sistema ACEPTA ÚNICAMENTE URLs de GitHub.\n",
    "\n",
    "Debes enviar solo el enlace del repositorio GitHub de tu proyecto, preferiblemente sin deploy.\n",
    "\n",
    "Después de agregar la URL de tu proyecto, descarga la insignia que aparecerá al hacer clic en el botón de envío y, luego, envía tu proyecto.\n",
    "\n",
    "Tienes 5 intentos para entregar tu proyecto.\n",
    "\n",
    "Después de la entrega del desafío, ¡DEBES COMPLETAR EL CURSO Y GENERAR TU CERTIFICADO!\n",
    "Descarga tu insignia, compártela en LinkedIn y en todas tus redes sociales usando los hashtags #AluraLatam y #oraclenexteducation.\n",
    "\n",
    "No olvides revisar este video que preparamos para ti con el paso a paso descrito arriba."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e00c2d",
   "metadata": {},
   "source": [
    "#  03 Importancia del Desafio\n",
    "## Desafío Telecom X parte 2\n",
    "El Desafío Telecom X parte 2 ofrece una oportunidad única para aplicar conocimientos fundamentales de estadística, regresión lineal y machine learning, además de habilidades esenciales en ciencia de datos, en un escenario empresarial real.\n",
    "\n",
    "### Aplicación práctica del conocimiento\n",
    "\n",
    "`En este desafío, pondrás en práctica conceptos fundamentales de estadística, esenciales para comprender el comportamiento de los datos y fundamentar decisiones analíticas.`\n",
    "\n",
    "`Uno de los pasos principales será preparar y separar los datos de forma adecuada para la creación de modelos predictivos, asegurando un equilibrio entre los datos de entrenamiento y prueba — algo indispensable para construir modelos confiables.`\n",
    "\n",
    "`Al realizar el análisis de correlación entre variables, será posible identificar qué factores influyen más en la cancelación de servicios (churn). Esto permitirá aplicar la regresión lineal como herramienta para modelar estas relaciones y entender el impacto de cada variable en el comportamiento de los clientes.`\n",
    "\n",
    "`Con ello, construirás una base sólida para el desarrollo de modelos de machine learning orientados a la predicción de churn, ayudando a la empresa a anticipar el riesgo de pérdida de clientes y tomar decisiones estratégicas para reducir ese impacto.`\n",
    "\n",
    "`Este desafío no solo contribuye a tu crecimiento en el área de Ciencia de Datos, sino que también demuestra en la práctica cómo la ciencia de datos puede utilizarse para resolver problemas reales enfrentados por empresas en el mercado.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967f5c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   customerID Churn                                           customer  \\\n",
      "0  0002-ORFBO    No  {'gender': 'Female', 'SeniorCitizen': 0, 'Part...   \n",
      "1  0003-MKNFE    No  {'gender': 'Male', 'SeniorCitizen': 0, 'Partne...   \n",
      "2  0004-TLHLJ   Yes  {'gender': 'Male', 'SeniorCitizen': 0, 'Partne...   \n",
      "3  0011-IGKFF   Yes  {'gender': 'Male', 'SeniorCitizen': 1, 'Partne...   \n",
      "4  0013-EXCHZ   Yes  {'gender': 'Female', 'SeniorCitizen': 1, 'Part...   \n",
      "\n",
      "                                             phone  \\\n",
      "0   {'PhoneService': 'Yes', 'MultipleLines': 'No'}   \n",
      "1  {'PhoneService': 'Yes', 'MultipleLines': 'Yes'}   \n",
      "2   {'PhoneService': 'Yes', 'MultipleLines': 'No'}   \n",
      "3   {'PhoneService': 'Yes', 'MultipleLines': 'No'}   \n",
      "4   {'PhoneService': 'Yes', 'MultipleLines': 'No'}   \n",
      "\n",
      "                                            internet  \\\n",
      "0  {'InternetService': 'DSL', 'OnlineSecurity': '...   \n",
      "1  {'InternetService': 'DSL', 'OnlineSecurity': '...   \n",
      "2  {'InternetService': 'Fiber optic', 'OnlineSecu...   \n",
      "3  {'InternetService': 'Fiber optic', 'OnlineSecu...   \n",
      "4  {'InternetService': 'Fiber optic', 'OnlineSecu...   \n",
      "\n",
      "                                             account  \n",
      "0  {'Contract': 'One year', 'PaperlessBilling': '...  \n",
      "1  {'Contract': 'Month-to-month', 'PaperlessBilli...  \n",
      "2  {'Contract': 'Month-to-month', 'PaperlessBilli...  \n",
      "3  {'Contract': 'Month-to-month', 'PaperlessBilli...  \n",
      "4  {'Contract': 'Month-to-month', 'PaperlessBilli...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Especifica la ruta a tu archivo JSON\n",
    "ruta_archivo = '../data/TelecomX_Data.json'\n",
    "\n",
    "# Abre el archivo JSON y carga los datos\n",
    "with open(ruta_archivo, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Como el JSON que mostraste parece ser una lista de diccionarios,\n",
    "# podemos directamente crear un DataFrame a partir de esa lista.\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Vamos a ver las primeras filas del DataFrame para verificar la extracción\n",
    "print(df.head())\n",
    "\n",
    "# Eliminar la columna 'customerID' si existe\n",
    "if 'customerID' in df.columns:\n",
    "    df = df.drop('customerID', axis=1)\n",
    "    print(\"Columna 'customerID' eliminada.\")\n",
    "else:\n",
    "    print(\"La columna 'customerID' no se encontró en el DataFrame.\")\n",
    "\n",
    "print(\"\\nColumnas restantes:\")\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12cf65fb",
   "metadata": {},
   "source": [
    "## Claude:\n",
    "# 🚀 Plan de Acción para la Predicción de Cancelación (Churn)\n",
    "\n",
    "## 1. Preparación de los Datos para el Modelado\n",
    "\n",
    "### Tratamiento de valores nulos\n",
    "- **Imputación**: media, mediana, moda, regresión\n",
    "- **Eliminación** de filas/columnas\n",
    "- **Algoritmos** que manejen valores faltantes\n",
    "\n",
    "### Tratamiento de valores atípicos (outliers)\n",
    "- **Eliminación**\n",
    "- **Transformación**\n",
    "- **Winsorización**\n",
    "\n",
    "### Codificación de variables categóricas\n",
    "- **One-Hot Encoding**: variables nominales (sin orden intrínseco)\n",
    "- **Label Encoding** u **Ordinal Encoding**: variables ordinales (con orden)\n",
    "\n",
    "### Normalización/Estandarización de variables numéricas\n",
    "- **Normalización (Min-Max Scaling)**: escala entre 0 y 1\n",
    "- **Estandarización (Standard Scaling)**: media 0 y desviación estándar 1\n",
    "\n",
    "### Creación de nuevas características (Feature Engineering)\n",
    "- **Combinar** o **transformar** características existentes\n",
    "- Ejemplo: \"cargo mensual\" + \"meses de contrato\" = \"gasto total\"\n",
    "\n",
    "## 2. Análisis de Correlación y Selección de Variables\n",
    "\n",
    "### Matriz de correlación\n",
    "- **Relaciones** entre variables numéricas\n",
    "- Identificar **multicolinealidad**\n",
    "\n",
    "### Selección de variables (Feature Selection)\n",
    "- **Métodos de filtro**: χ², ANOVA, Information Gain\n",
    "- **Métodos de envoltura**: Recursive Feature Elimination (RFE)\n",
    "- **Métodos incrustados**: Lasso/Ridge Regression, árboles de decisión\n",
    "\n",
    "### Análisis de la importancia de las características\n",
    "- **Feature Importance** en modelos basados en árboles\n",
    "\n",
    "## 3. Entrenamiento de Dos o Más Modelos de Clasificación\n",
    "\n",
    "### Modelos recomendados para clasificación binaria\n",
    "- **Regresión Logística**: interpretable y eficaz\n",
    "- **Random Forest** o **Gradient Boosting** (LightGBM/XGBoost)\n",
    "\n",
    "### Pasos clave\n",
    "- **División de datos**: 70/30 o 80/20 (estratificada)\n",
    "- **Entrenamiento** con conjunto de entrenamiento\n",
    "- **Ajuste de hiperparámetros**: GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "## 4. Evaluación del Rendimiento de los Modelos con Métricas\n",
    "\n",
    "### Métricas fundamentales para clases desbalanceadas\n",
    "- **Matriz de Confusión**: VP, VN, FP, FN\n",
    "- **Precisión (Precision)**: predicciones positivas correctas\n",
    "- **Recall (Sensibilidad)**: casos positivos reales identificados\n",
    "- **F1-Score**: media armónica de precisión y recall\n",
    "- **Curva ROC** y **AUC**: rendimiento general de clasificación\n",
    "- **Curva Precision-Recall**: para conjuntos desbalanceados\n",
    "\n",
    "## 5. Interpretación de los Resultados\n",
    "\n",
    "### Importancia de las características\n",
    "- **Métodos intrínsecos**: feature_importances_ en árboles\n",
    "- **Técnicas post-hoc**: SHAP, LIME\n",
    "\n",
    "### Análisis de coeficientes\n",
    "- **Regresión Logística**: interpretar dirección y magnitud del impacto\n",
    "\n",
    "## 6. Creación de una Conclusión Estratégica\n",
    "\n",
    "### Principales factores que influyen en la cancelación\n",
    "- Identificar **3-5 variables** más importantes\n",
    "\n",
    "### Recomendaciones estratégicas\n",
    "- **Duración del contrato**: incentivos por contratos largos\n",
    "- **Tipos de servicios**: revisar ofertas problemáticas\n",
    "- **Cargos mensuales**: planes alternativos o paquetes\n",
    "\n",
    "### Limitaciones del modelo y próximos pasos\n",
    "- **Transparencia** sobre limitaciones\n",
    "- **Futuras mejoras**: más modelos, feature engineering, nuevos datos\n",
    "\n",
    "---\n",
    "\n",
    "**Palabras clave destacadas**: preparación de datos, tratamiento de valores nulos, outliers, codificación, normalización, feature engineering, correlación, selección de variables, clasificación binaria, regresión logística, random forest, gradient boosting, métricas de evaluación, matriz de confusión, precisión, recall, F1-score, ROC, AUC, interpretación, importancia de características, conclusión estratégica."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7914425",
   "metadata": {},
   "source": [
    "# Prompt con los datos de Trello:\n",
    "# 🚀 Desafío TelecomX - Predicción de Cancelación de Clientes (Churn)\n",
    "\n",
    "## Objetivo Principal\n",
    "Desarrollar modelos de Machine Learning para predecir la cancelación de clientes en TelecomX, identificando los factores más influyentes y proponiendo estrategias de retención.\n",
    "\n",
    "---\n",
    "\n",
    "## 📋 Parte 1: Preparación y Carga de Datos\n",
    "\n",
    "### 1.1 Carga del Dataset\n",
    "**Descripción:** Carga el archivo CSV que contiene los datos tratados anteriormente.\n",
    "\n",
    "**Instrucciones:**\n",
    "- Utiliza el mismo archivo que limpiaste y organizaste en la Parte 1 del desafío TelecomX\n",
    "- Debe contener solo las columnas relevantes, ya con los datos corregidos y estandarizados\n",
    "- Código de referencia disponible:\n",
    "```python\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Especifica la ruta a tu archivo JSON\n",
    "ruta_archivo = '../data/TelecomX_Data.json'\n",
    "\n",
    "# Abre el archivo JSON y carga los datos\n",
    "with open(ruta_archivo, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Crear DataFrame a partir de la lista de diccionarios\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Verificar la extracción\n",
    "print(df.head())\n",
    "```\n",
    "\n",
    "### 1.2 Limpieza de Columnas\n",
    "**Descripción:** Elimina columnas que no aportan valor al análisis o a los modelos predictivos.\n",
    "\n",
    "**Instrucciones:**\n",
    "- Eliminar identificadores únicos (por ejemplo, ID del cliente)\n",
    "- Remover columnas que no ayudan en la predicción de cancelación\n",
    "- Estas columnas pueden perjudicar el desempeño de los modelos\n",
    "\n",
    "---\n",
    "\n",
    "## 🔧 Parte 2: Preprocesamiento de Datos\n",
    "\n",
    "### 2.1 Codificación de Variables Categóricas\n",
    "**Descripción:** Transforma las variables categóricas a formato numérico para hacerlas compatibles con los algoritmos de machine learning.\n",
    "\n",
    "**Instrucciones:**\n",
    "- Utiliza un método de codificación adecuado como **one-hot encoding**\n",
    "- Considera usar `get_dummies()` o `OneHotEncoder`\n",
    "\n",
    "💡 **Sugerencia:** Consulta documentación sobre cuándo usar get_dummies o OneHotEncoder\n",
    "\n",
    "### 2.2 Análisis de Balance de Clases\n",
    "**Descripción:** Calcula la proporción de clientes que cancelaron en relación con los que permanecieron activos.\n",
    "\n",
    "**Instrucciones:**\n",
    "- Evalúa si existe un desbalance entre las clases\n",
    "- Esto puede impactar en los modelos predictivos y en el análisis de resultados\n",
    "- Usa `value_counts()` de pandas para obtener esta proporción\n",
    "\n",
    "💡 **Sugerencia:** Consulta la documentación oficial de value_counts()\n",
    "\n",
    "### 2.3 Técnicas de Balanceo (Opcional)\n",
    "**Descripción:** Si deseas profundizar en el análisis, aplica técnicas de balanceo como undersampling o oversampling.\n",
    "\n",
    "**Instrucciones:**\n",
    "- En situaciones de fuerte desbalanceo, herramientas como **SMOTE** pueden ser útiles\n",
    "- Generar ejemplos sintéticos de la clase minoritaria\n",
    "\n",
    "💡 **Sugerencia:** Lee sobre manejo de desbalanceo de clases en recursos especializados\n",
    "\n",
    "### 2.4 Normalización y Estandarización\n",
    "**Descripción:** Evalúa la necesidad de normalizar o estandarizar los datos, según los modelos que se aplicarán.\n",
    "\n",
    "**Instrucciones:**\n",
    "- **Modelos que REQUIEREN normalización:** KNN, SVM, Regresión Logística, Redes Neuronales\n",
    "- **Modelos que NO requieren normalización:** Decision Tree, Random Forest, XGBoost\n",
    "- Aplicar según el tipo de modelo seleccionado\n",
    "\n",
    "💡 **Sugerencia:** Consulta artículos sobre normalización y estandarización en Machine Learning\n",
    "\n",
    "---\n",
    "\n",
    "## 📊 Parte 3: Análisis Exploratorio y Correlaciones\n",
    "\n",
    "### 3.1 Matriz de Correlación\n",
    "**Descripción:** Visualiza la matriz de correlación para identificar relaciones entre las variables numéricas.\n",
    "\n",
    "**Instrucciones:**\n",
    "- Identificar relaciones entre variables numéricas\n",
    "- Prestar especial atención a variables con mayor correlación con la cancelación\n",
    "- Estas pueden ser fuertes candidatas para el modelo predictivo\n",
    "\n",
    "### 3.2 Análisis de Variables Específicas\n",
    "**Descripción:** Investiga cómo variables específicas se relacionan con la cancelación.\n",
    "\n",
    "**Variables a analizar:**\n",
    "- **Tiempo de contrato × Cancelación**\n",
    "- **Gasto total × Cancelación**\n",
    "\n",
    "**Instrucciones:**\n",
    "- Utiliza gráficos como **boxplots** o **scatter plots**\n",
    "- Visualizar patrones y posibles tendencias\n",
    "- Identificar insights relevantes para el negocio\n",
    "\n",
    "---\n",
    "\n",
    "## 🤖 Parte 4: Desarrollo de Modelos\n",
    "\n",
    "### 4.1 División del Dataset\n",
    "**Descripción:** Divide el conjunto de datos en entrenamiento y prueba para evaluar el rendimiento del modelo.\n",
    "\n",
    "**Instrucciones:**\n",
    "- División común: **70% entrenamiento / 30% prueba** o **80/20**\n",
    "- Depende del tamaño de la base de datos\n",
    "- Usar estratificación si hay desbalance de clases\n",
    "\n",
    "### 4.2 Creación de Modelos\n",
    "**Descripción:** Crea al menos dos modelos diferentes para predecir la cancelación de clientes.\n",
    "\n",
    "**Modelos recomendados:**\n",
    "1. **Modelo que requiere normalización:** Regresión Logística o KNN\n",
    "2. **Modelo que no requiere normalización:** Árbol de Decisión o Random Forest\n",
    "\n",
    "**Justificación:**\n",
    "- **Regresión Logística / KNN:** Sensibles a la escala de los datos, normalización importante\n",
    "- **Árbol de Decisión / Random Forest:** No dependen de la escala de los datos\n",
    "\n",
    "💡 **Nota:** La decisión de aplicar o no la normalización depende de los modelos seleccionados\n",
    "\n",
    "---\n",
    "\n",
    "## 📈 Parte 5: Evaluación y Comparación de Modelos\n",
    "\n",
    "### 5.1 Métricas de Evaluación\n",
    "**Descripción:** Evalúa cada modelo utilizando las siguientes métricas.\n",
    "\n",
    "**Métricas obligatorias:**\n",
    "- **Exactitud (Accuracy)**\n",
    "- **Precisión (Precision)**\n",
    "- **Recall (Sensibilidad)**\n",
    "- **F1-score**\n",
    "- **Matriz de confusión**\n",
    "\n",
    "### 5.2 Análisis Crítico y Comparación\n",
    "**Descripción:** Realiza un análisis crítico y compara los modelos.\n",
    "\n",
    "**Preguntas clave:**\n",
    "- ¿Cuál modelo tuvo el mejor desempeño?\n",
    "- ¿Algún modelo presentó overfitting o underfitting?\n",
    "\n",
    "**Definiciones:**\n",
    "- **Overfitting:** El modelo aprende demasiado sobre los datos de entrenamiento, perdiendo capacidad de generalizar\n",
    "  - *Solución:* Reducir complejidad del modelo o aumentar datos de entrenamiento\n",
    "- **Underfitting:** El modelo no captura bien las tendencias de los datos, es demasiado simple\n",
    "  - *Solución:* Aumentar complejidad del modelo o ajustar parámetros\n",
    "\n",
    "---\n",
    "\n",
    "## 🔍 Parte 6: Análisis de Importancia de Variables\n",
    "\n",
    "### 6.1 Interpretación por Tipo de Modelo\n",
    "**Descripción:** Después de elegir los modelos, realiza el análisis de las variables más relevantes para la predicción de cancelación.\n",
    "\n",
    "**Por tipo de modelo:**\n",
    "\n",
    "- **Regresión Logística:** Investigar los coeficientes de las variables\n",
    "- **KNN:** Observar cómo los vecinos más cercanos influyen en la clasificación\n",
    "- **Random Forest:** Utilizar la importancia de variables proporcionada por el modelo\n",
    "- **SVM:** Analizar los coeficientes de los vectores de soporte\n",
    "- **Otros Modelos:** Considerar métricas específicas (coeficientes en modelos lineales, pesos en redes neuronales, importancia en técnicas de boosting)\n",
    "\n",
    "---\n",
    "\n",
    "## 📋 Parte 7: Informe Final y Recomendaciones\n",
    "\n",
    "### 7.1 Informe Detallado\n",
    "**Descripción:** Elabora un informe detallado, destacando los factores que más influyen en la cancelación.\n",
    "\n",
    "**Incluir:**\n",
    "- Factores más influyentes basados en las variables seleccionadas\n",
    "- Rendimiento de cada modelo\n",
    "- Comparación entre modelos\n",
    "- Limitaciones y posibles mejoras\n",
    "\n",
    "### 7.2 Estrategias de Retención\n",
    "**Descripción:** Identifica los principales factores que afectan la cancelación de clientes y propone estrategias de retención.\n",
    "\n",
    "**Deliverables:**\n",
    "- Principales factores de cancelación\n",
    "- Estrategias de retención basadas en los resultados\n",
    "- Recomendaciones accionables para el negocio\n",
    "- Próximos pasos y mejoras futuras\n",
    "\n",
    "---\n",
    "\n",
    "## 🎯 Criterios de Éxito\n",
    "\n",
    "- **Preparación de datos:** Limpieza, codificación y normalización correctas\n",
    "- **Análisis exploratorio:** Insights relevantes sobre correlaciones y patrones\n",
    "- **Modelado:** Al menos 2 modelos diferentes con justificación técnica\n",
    "- **Evaluación:** Uso correcto de métricas y análisis crítico\n",
    "- **Interpretación:** Identificación clara de variables más importantes\n",
    "- **Conclusiones:** Recomendaciones estratégicas basadas en evidencia\n",
    "\n",
    "---\n",
    "\n",
    "## 📚 Recursos Adicionales\n",
    "\n",
    "- Documentación de pandas para manipulación de datos\n",
    "- Scikit-learn para modelos de Machine Learning\n",
    "- Matplotlib/Seaborn para visualizaciones\n",
    "- Artículos especializados en desbalanceo de clases y normalización\n",
    "- Guías de interpretación de modelos de ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ff0fba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   customerID Churn                                           customer  \\\n",
      "0  0002-ORFBO    No  {'gender': 'Female', 'SeniorCitizen': 0, 'Part...   \n",
      "1  0003-MKNFE    No  {'gender': 'Male', 'SeniorCitizen': 0, 'Partne...   \n",
      "2  0004-TLHLJ   Yes  {'gender': 'Male', 'SeniorCitizen': 0, 'Partne...   \n",
      "3  0011-IGKFF   Yes  {'gender': 'Male', 'SeniorCitizen': 1, 'Partne...   \n",
      "4  0013-EXCHZ   Yes  {'gender': 'Female', 'SeniorCitizen': 1, 'Part...   \n",
      "\n",
      "                                             phone  \\\n",
      "0   {'PhoneService': 'Yes', 'MultipleLines': 'No'}   \n",
      "1  {'PhoneService': 'Yes', 'MultipleLines': 'Yes'}   \n",
      "2   {'PhoneService': 'Yes', 'MultipleLines': 'No'}   \n",
      "3   {'PhoneService': 'Yes', 'MultipleLines': 'No'}   \n",
      "4   {'PhoneService': 'Yes', 'MultipleLines': 'No'}   \n",
      "\n",
      "                                            internet  \\\n",
      "0  {'InternetService': 'DSL', 'OnlineSecurity': '...   \n",
      "1  {'InternetService': 'DSL', 'OnlineSecurity': '...   \n",
      "2  {'InternetService': 'Fiber optic', 'OnlineSecu...   \n",
      "3  {'InternetService': 'Fiber optic', 'OnlineSecu...   \n",
      "4  {'InternetService': 'Fiber optic', 'OnlineSecu...   \n",
      "\n",
      "                                             account  \n",
      "0  {'Contract': 'One year', 'PaperlessBilling': '...  \n",
      "1  {'Contract': 'Month-to-month', 'PaperlessBilli...  \n",
      "2  {'Contract': 'Month-to-month', 'PaperlessBilli...  \n",
      "3  {'Contract': 'Month-to-month', 'PaperlessBilli...  \n",
      "4  {'Contract': 'Month-to-month', 'PaperlessBilli...  \n",
      "Columna 'customerID' eliminada.\n",
      "\n",
      "Columnas restantes:\n",
      "Index(['Churn', 'customer', 'phone', 'internet', 'account'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Especifica la ruta a tu archivo JSON\n",
    "ruta_archivo = '../data/TelecomX_Data.json'\n",
    "\n",
    "# Abre el archivo JSON y carga los datos\n",
    "with open(ruta_archivo, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Como el JSON que mostraste parece ser una lista de diccionarios,\n",
    "# podemos directamente crear un DataFrame a partir de esa lista.\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Vamos a ver las primeras filas del DataFrame para verificar la extracción\n",
    "print(df.head())\n",
    "\n",
    "# Eliminar la columna 'customerID' si existe\n",
    "if 'customerID' in df.columns:\n",
    "    df = df.drop('customerID', axis=1)\n",
    "    print(\"Columna 'customerID' eliminada.\")\n",
    "else:\n",
    "    print(\"La columna 'customerID' no se encontró en el DataFrame.\")\n",
    "\n",
    "print(\"\\nColumnas restantes:\")\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d14b6d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame después de aplanar todas las columnas anidadas:\n",
      "  Churn  gender  SeniorCitizen Partner Dependents  tenure PhoneService  \\\n",
      "0    No  Female              0     Yes        Yes       9          Yes   \n",
      "1    No    Male              0      No         No       9          Yes   \n",
      "2   Yes    Male              0      No         No       4          Yes   \n",
      "3   Yes    Male              1     Yes         No      13          Yes   \n",
      "4   Yes  Female              1     Yes         No       3          Yes   \n",
      "\n",
      "  MultipleLines InternetService OnlineSecurity OnlineBackup DeviceProtection  \\\n",
      "0            No             DSL             No          Yes               No   \n",
      "1           Yes             DSL             No           No               No   \n",
      "2            No     Fiber optic             No           No              Yes   \n",
      "3            No     Fiber optic             No          Yes              Yes   \n",
      "4            No     Fiber optic             No           No               No   \n",
      "\n",
      "  TechSupport StreamingTV StreamingMovies        Contract PaperlessBilling  \\\n",
      "0         Yes         Yes              No        One year              Yes   \n",
      "1          No          No             Yes  Month-to-month               No   \n",
      "2          No          No              No  Month-to-month              Yes   \n",
      "3          No         Yes             Yes  Month-to-month              Yes   \n",
      "4         Yes         Yes              No  Month-to-month              Yes   \n",
      "\n",
      "      PaymentMethod  Charges.Monthly Charges.Total  \n",
      "0      Mailed check             65.6         593.3  \n",
      "1      Mailed check             59.9         542.4  \n",
      "2  Electronic check             73.9        280.85  \n",
      "3  Electronic check             98.0       1237.85  \n",
      "4      Mailed check             83.9         267.4  \n",
      "\n",
      "Número de columnas después de aplanar: 20\n",
      "\n",
      "Tipos de datos actuales de las columnas:\n",
      "Churn                object\n",
      "gender               object\n",
      "SeniorCitizen         int64\n",
      "Partner              object\n",
      "Dependents           object\n",
      "tenure                int64\n",
      "PhoneService         object\n",
      "MultipleLines        object\n",
      "InternetService      object\n",
      "OnlineSecurity       object\n",
      "OnlineBackup         object\n",
      "DeviceProtection     object\n",
      "TechSupport          object\n",
      "StreamingTV          object\n",
      "StreamingMovies      object\n",
      "Contract             object\n",
      "PaperlessBilling     object\n",
      "PaymentMethod        object\n",
      "Charges.Monthly     float64\n",
      "Charges.Total        object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Aplanar la columna 'customer'\n",
    "customer_df = pd.json_normalize(df['customer'])\n",
    "df = pd.concat([df.drop('customer', axis=1), customer_df], axis=1)\n",
    "\n",
    "# Aplanar la columna 'phone'\n",
    "phone_df = pd.json_normalize(df['phone'])\n",
    "df = pd.concat([df.drop('phone', axis=1), phone_df], axis=1)\n",
    "\n",
    "# Aplanar la columna 'internet'\n",
    "internet_df = pd.json_normalize(df['internet'])\n",
    "df = pd.concat([df.drop('internet', axis=1), internet_df], axis=1)\n",
    "\n",
    "# Aplanar la columna 'account'\n",
    "account_df = pd.json_normalize(df['account'])\n",
    "df = pd.concat([df.drop('account', axis=1), account_df], axis=1)\n",
    "\n",
    "print(\"DataFrame después de aplanar todas las columnas anidadas:\")\n",
    "print(df.head())\n",
    "print(f\"\\nNúmero de columnas después de aplanar: {df.shape[1]}\")\n",
    "print(\"\\nTipos de datos actuales de las columnas:\")\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32a9502",
   "metadata": {},
   "source": [
    "## 🧹 Limpieza y Conversión de Charges.Total\n",
    "Vamos a inspeccionar y corregir la columna Charges.Total. Es común que los valores vacíos o no numéricos en esta columna representen clientes nuevos que aún no han acumulado cargos totales. En estos casos, suelen ser cero o un valor pequeño.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac777570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores únicos en 'Charges.Total' antes de la conversión (primeros 20):\n",
      "['593.3' '542.4' '280.85' '1237.85' '267.4' '571.45' '7904.25' '5377.8'\n",
      " '340.35' '5957.9' '2460.55' '8456.75' '351.5' '7261.25' '2560.1' '6849.4'\n",
      " '1993.2' '72.1' '2791.5' '25.1']\n",
      "\n",
      "Número de valores NaN en 'Charges.Total' después de la conversión: 11\n",
      "Tipo de dato de 'Charges.Total' después de la limpieza: float64\n",
      "\n",
      "Primeras filas del DataFrame con 'Charges.Total' limpio:\n",
      "  Churn  gender  SeniorCitizen Partner Dependents  tenure PhoneService  \\\n",
      "0    No  Female              0     Yes        Yes       9          Yes   \n",
      "1    No    Male              0      No         No       9          Yes   \n",
      "2   Yes    Male              0      No         No       4          Yes   \n",
      "3   Yes    Male              1     Yes         No      13          Yes   \n",
      "4   Yes  Female              1     Yes         No       3          Yes   \n",
      "\n",
      "  MultipleLines InternetService OnlineSecurity OnlineBackup DeviceProtection  \\\n",
      "0            No             DSL             No          Yes               No   \n",
      "1           Yes             DSL             No           No               No   \n",
      "2            No     Fiber optic             No           No              Yes   \n",
      "3            No     Fiber optic             No          Yes              Yes   \n",
      "4            No     Fiber optic             No           No               No   \n",
      "\n",
      "  TechSupport StreamingTV StreamingMovies        Contract PaperlessBilling  \\\n",
      "0         Yes         Yes              No        One year              Yes   \n",
      "1          No          No             Yes  Month-to-month               No   \n",
      "2          No          No              No  Month-to-month              Yes   \n",
      "3          No         Yes             Yes  Month-to-month              Yes   \n",
      "4         Yes         Yes              No  Month-to-month              Yes   \n",
      "\n",
      "      PaymentMethod  Charges.Monthly  Charges.Total  \n",
      "0      Mailed check             65.6         593.30  \n",
      "1      Mailed check             59.9         542.40  \n",
      "2  Electronic check             73.9         280.85  \n",
      "3  Electronic check             98.0        1237.85  \n",
      "4      Mailed check             83.9         267.40  \n"
     ]
    }
   ],
   "source": [
    "# Inspeccionar valores únicos en Charges.Total para entender el problema\n",
    "print(\"Valores únicos en 'Charges.Total' antes de la conversión (primeros 20):\")\n",
    "print(df['Charges.Total'].unique()[:20])\n",
    "\n",
    "# Reemplazar espacios vacíos o ' ' con NaN y luego convertir a numérico\n",
    "# El argumento errors='coerce' convertirá cualquier valor no numérico en NaN\n",
    "df['Charges.Total'] = pd.to_numeric(df['Charges.Total'], errors='coerce')\n",
    "\n",
    "# Verificar si hay valores NaN después de la conversión\n",
    "print(f\"\\nNúmero de valores NaN en 'Charges.Total' después de la conversión: {df['Charges.Total'].isnull().sum()}\")\n",
    "\n",
    "# Llenar los valores NaN (por ejemplo, con 0, la media, o la mediana).\n",
    "# Para cargos totales, es razonable asumir 0 para nuevos clientes sin cargos registrados.\n",
    "df['Charges.Total'] = df['Charges.Total'].fillna(0) # Opcional: df['Charges.Total'].mean() para la media\n",
    "\n",
    "# Verificar el tipo de dato después de la limpieza\n",
    "print(f\"Tipo de dato de 'Charges.Total' después de la limpieza: {df['Charges.Total'].dtype}\")\n",
    "\n",
    "print(\"\\nPrimeras filas del DataFrame con 'Charges.Total' limpio:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccad6697",
   "metadata": {},
   "source": [
    "## 🔄 Codificación de Variables Categóricas\n",
    "En este paso, transformaremos todas las columnas de tipo object (que son categóricas) en un formato numérico que los algoritmos de Machine Learning puedan entender. Usaremos pd.get_dummies para aplicar One-Hot Encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a9b320c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Columnas categóricas a codificar: ['gender', 'Partner', 'Dependents', 'PhoneService', 'MultipleLines', 'InternetService', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies', 'Contract', 'PaperlessBilling', 'PaymentMethod']\n",
      "\n",
      "DataFrame después de One-Hot Encoding:\n",
      "  Churn  SeniorCitizen  tenure  Charges.Monthly  Charges.Total  gender_Male  \\\n",
      "0    No              0       9             65.6         593.30            0   \n",
      "1    No              0       9             59.9         542.40            1   \n",
      "2   Yes              0       4             73.9         280.85            1   \n",
      "3   Yes              1      13             98.0        1237.85            1   \n",
      "4   Yes              1       3             83.9         267.40            0   \n",
      "\n",
      "   Partner_Yes  Dependents_Yes  PhoneService_Yes  \\\n",
      "0            1               1                 1   \n",
      "1            0               0                 1   \n",
      "2            0               0                 1   \n",
      "3            1               0                 1   \n",
      "4            1               0                 1   \n",
      "\n",
      "   MultipleLines_No phone service  ...  StreamingTV_No internet service  \\\n",
      "0                               0  ...                                0   \n",
      "1                               0  ...                                0   \n",
      "2                               0  ...                                0   \n",
      "3                               0  ...                                0   \n",
      "4                               0  ...                                0   \n",
      "\n",
      "   StreamingTV_Yes  StreamingMovies_No internet service  StreamingMovies_Yes  \\\n",
      "0                1                                    0                    0   \n",
      "1                0                                    0                    1   \n",
      "2                0                                    0                    0   \n",
      "3                1                                    0                    1   \n",
      "4                1                                    0                    0   \n",
      "\n",
      "   Contract_One year  Contract_Two year  PaperlessBilling_Yes  \\\n",
      "0                  1                  0                     1   \n",
      "1                  0                  0                     0   \n",
      "2                  0                  0                     1   \n",
      "3                  0                  0                     1   \n",
      "4                  0                  0                     1   \n",
      "\n",
      "   PaymentMethod_Credit card (automatic)  PaymentMethod_Electronic check  \\\n",
      "0                                      0                               0   \n",
      "1                                      0                               0   \n",
      "2                                      0                               1   \n",
      "3                                      0                               1   \n",
      "4                                      0                               0   \n",
      "\n",
      "   PaymentMethod_Mailed check  \n",
      "0                           1  \n",
      "1                           1  \n",
      "2                           0  \n",
      "3                           0  \n",
      "4                           1  \n",
      "\n",
      "[5 rows x 31 columns]\n",
      "\n",
      "Número de columnas después de encoding: 31\n",
      "\n",
      "Tipos de datos de las columnas después de encoding:\n",
      "uint8      26\n",
      "int64       2\n",
      "float64     2\n",
      "object      1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Identificar columnas categóricas (tipo 'object')\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Excluir la columna objetivo 'Churn' si está en las categóricas para no encodificarla aún\n",
    "if 'Churn' in categorical_cols:\n",
    "    categorical_cols.remove('Churn')\n",
    "\n",
    "print(f\"\\nColumnas categóricas a codificar: {categorical_cols}\")\n",
    "\n",
    "# Aplicar One-Hot Encoding\n",
    "# drop_first=True evita la trampa de las variables dummy (multicolinealidad)\n",
    "df = pd.get_dummies(df, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "print(\"\\nDataFrame después de One-Hot Encoding:\")\n",
    "print(df.head())\n",
    "print(f\"\\nNúmero de columnas después de encoding: {df.shape[1]}\")\n",
    "print(\"\\nTipos de datos de las columnas después de encoding:\")\n",
    "# Esto nos dará un resumen de cuántas columnas hay por cada tipo de dato\n",
    "print(df.dtypes.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c9e347",
   "metadata": {},
   "source": [
    "## ¡Genial! Has completado exitosamente la codificación de todas las variables categóricas. Tu DataFrame ahora está casi listo para el modelado, con todas las características en formato numérico, a excepción de la columna Churn que sigue siendo object.\n",
    "\n",
    "Ahora, vamos a realizar el análisis de desbalanceo de clases y, crucialmente, convertir la columna Churn a un formato numérico (0 y 1) para que tus modelos de Machine Learning puedan procesarla.\n",
    "\n",
    "### 📊 Análisis de Desbalanceo de Clases y Conversión de 'Churn'\n",
    "Evaluar la proporción de clientes que cancelaron versus los que no es fundamental, ya que un desbalanceo significativo puede sesgar tus modelos. Además, transformaremos \"Yes\"/\"No\" en 1/0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00f1b09f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conteo de clientes por estado de Churn:\n",
      "No     5174\n",
      "Yes    1869\n",
      "        224\n",
      "Name: Churn, dtype: int64\n",
      "\n",
      "Proporción de Churn:\n",
      "No Churn: 71.20%\n",
      "Churn: 25.72%\n",
      "\n",
      "Proporción numérica de Churn (0=No, 1=Yes):\n",
      "0.0    0.73463\n",
      "1.0    0.26537\n",
      "Name: Churn, dtype: float64\n",
      "\n",
      "¡Advertencia! Existe un **desbalanceo significativo** en las clases de Churn.\n",
      "Considera aplicar técnicas de balanceo como **SMOTE** si los modelos iniciales no rinden bien, especialmente en métricas como Recall para la clase 'Churn'.\n",
      "\n",
      "Primeras filas del DataFrame con 'Churn' convertido a numérico:\n",
      "   Churn  SeniorCitizen  tenure  Charges.Monthly  Charges.Total  gender_Male  \\\n",
      "0    0.0              0       9             65.6         593.30            0   \n",
      "1    0.0              0       9             59.9         542.40            1   \n",
      "2    1.0              0       4             73.9         280.85            1   \n",
      "3    1.0              1      13             98.0        1237.85            1   \n",
      "4    1.0              1       3             83.9         267.40            0   \n",
      "\n",
      "   Partner_Yes  Dependents_Yes  PhoneService_Yes  \\\n",
      "0            1               1                 1   \n",
      "1            0               0                 1   \n",
      "2            0               0                 1   \n",
      "3            1               0                 1   \n",
      "4            1               0                 1   \n",
      "\n",
      "   MultipleLines_No phone service  ...  StreamingTV_No internet service  \\\n",
      "0                               0  ...                                0   \n",
      "1                               0  ...                                0   \n",
      "2                               0  ...                                0   \n",
      "3                               0  ...                                0   \n",
      "4                               0  ...                                0   \n",
      "\n",
      "   StreamingTV_Yes  StreamingMovies_No internet service  StreamingMovies_Yes  \\\n",
      "0                1                                    0                    0   \n",
      "1                0                                    0                    1   \n",
      "2                0                                    0                    0   \n",
      "3                1                                    0                    1   \n",
      "4                1                                    0                    0   \n",
      "\n",
      "   Contract_One year  Contract_Two year  PaperlessBilling_Yes  \\\n",
      "0                  1                  0                     1   \n",
      "1                  0                  0                     0   \n",
      "2                  0                  0                     1   \n",
      "3                  0                  0                     1   \n",
      "4                  0                  0                     1   \n",
      "\n",
      "   PaymentMethod_Credit card (automatic)  PaymentMethod_Electronic check  \\\n",
      "0                                      0                               0   \n",
      "1                                      0                               0   \n",
      "2                                      0                               1   \n",
      "3                                      0                               1   \n",
      "4                                      0                               0   \n",
      "\n",
      "   PaymentMethod_Mailed check  \n",
      "0                           1  \n",
      "1                           1  \n",
      "2                           0  \n",
      "3                           0  \n",
      "4                           1  \n",
      "\n",
      "[5 rows x 31 columns]\n",
      "\n",
      "Tipo de dato de 'Churn' después de la conversión: float64\n"
     ]
    }
   ],
   "source": [
    "# Calcular la proporción de la clase 'Churn'\n",
    "churn_counts = df['Churn'].value_counts()\n",
    "total_customers = df.shape[0]\n",
    "\n",
    "print(\"Conteo de clientes por estado de Churn:\")\n",
    "print(churn_counts)\n",
    "\n",
    "print(\"\\nProporción de Churn:\")\n",
    "print(f\"No Churn: {churn_counts.get('No', 0) / total_customers:.2%}\")\n",
    "print(f\"Churn: {churn_counts.get('Yes', 0) / total_customers:.2%}\")\n",
    "\n",
    "# Convertir la columna 'Churn' a formato numérico (0 y 1)\n",
    "# Asumiendo 'Yes' para Churn (1) y 'No' para No Churn (0)\n",
    "df['Churn'] = df['Churn'].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "print(\"\\nProporción numérica de Churn (0=No, 1=Yes):\")\n",
    "print(df['Churn'].value_counts(normalize=True))\n",
    "\n",
    "if churn_counts.get('Yes', 0) / total_customers < 0.3 or churn_counts.get('Yes', 0) / total_customers > 0.7:\n",
    "    print(\"\\n¡Advertencia! Existe un **desbalanceo significativo** en las clases de Churn.\")\n",
    "    print(\"Considera aplicar técnicas de balanceo como **SMOTE** si los modelos iniciales no rinden bien, especialmente en métricas como Recall para la clase 'Churn'.\")\n",
    "else:\n",
    "    print(\"\\nLas clases de Churn parecen estar razonablemente balanceadas.\")\n",
    "\n",
    "print(\"\\nPrimeras filas del DataFrame con 'Churn' convertido a numérico:\")\n",
    "print(df.head())\n",
    "print(f\"\\nTipo de dato de 'Churn' después de la conversión: {df['Churn'].dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb14991",
   "metadata": {},
   "source": [
    "¡Excelente! La columna Churn ha sido correctamente convertida a un tipo numérico (float64), con 1 para \"Yes\" (canceló) y 0 para \"No\" (no canceló). También has confirmado el desbalanceo significativo en las clases, lo cual es una observación crucial para la fase de modelado.\n",
    "\n",
    "Ahora, procederemos con la normalización o estandarización de los datos numéricos. Como mencionamos, este paso es fundamental para los modelos que son sensibles a la escala de las características, como la Regresión Logística y KNN.\n",
    "\n",
    "### ⚖️ Normalización o Estandarización de Datos\n",
    "Vamos a aplicar la estandarización a las columnas numéricas de tu DataFrame. Esto transformará los datos para que tengan una media de 0 y una desviación estándar de 1."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "api-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
