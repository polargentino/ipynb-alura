{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5aa0c7d",
   "metadata": {},
   "source": [
    "## 01 Analisis de evasion de clientes\n",
    "¬°Hola! ¬°Qu√© bueno tenerte aqu√≠ para profundizar en este tema!\n",
    "\n",
    "Claro, puedo ayudarte con analog√≠as para entender mejor el rol del cient√≠fico de datos en este contexto:\n",
    "\n",
    "Imagina que eres un **detective**, pero en lugar de resolver cr√≠menes, resuelves **problemas de negocios**.\n",
    "\n",
    "### An√°lisis Exploratorio (Primera Parte del Challenge):\n",
    "\n",
    "Ser√≠a como la **investigaci√≥n inicial** del detective. Recopilas todas las **pistas** (datos), examinas la **escena del crimen** (situaci√≥n actual de la empresa), y tratas de entender **qu√© ha estado pasando** hasta ahora.\n",
    "\n",
    "### Construcci√≥n de Modelos Predictivos (Segunda Parte del Challenge):\n",
    "\n",
    "Aqu√≠, te conviertes en un **analista de perfiles criminales**. Usas la informaci√≥n que recopilaste para **predecir** qui√©nes son los clientes que est√°n a punto de \"escapar\" (evadirse). Es como crear un **perfil** de los clientes en riesgo bas√°ndote en su comportamiento pasado.\n",
    "\n",
    "### Herramientas y T√©cnicas:\n",
    "\n",
    "* **Python, Pandas, SQL, Matplotlib:** Son tus **herramientas forenses**.\n",
    "    * **Python:** Es tu **kit de herramientas** general.\n",
    "    * **Pandas:** Te ayuda a **organizar las pruebas** (datos).\n",
    "    * **SQL:** Te permite **interrogar a la base de datos** como si fuera un testigo.\n",
    "    * **Matplotlib:** Te ayuda a **visualizar la evidencia** para presentarla de manera clara.\n",
    "\n",
    "### Entrega Final:\n",
    "\n",
    "Tu **informe final** es el **notebook** que entregas. Debe incluir un **an√°lisis claro** (tu versi√≥n de los hechos), un **modelo evaluado** (la solidez de tu caso) y una **conclusi√≥n estrat√©gica** (tus recomendaciones para evitar futuros \"cr√≠menes\").\n",
    "\n",
    "¬øTe gustar√≠a que profundicemos en alguna de estas analog√≠as o en alg√∫n otro aspecto del tema?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4cf736",
   "metadata": {},
   "source": [
    "##  02 Trello del Desafio\n",
    "### Trello del Desaf√≠o\n",
    "Trello es una herramienta de colaboraci√≥n y gesti√≥n de proyectos que permite organizar tareas en tarjetas. Usar√°s esta herramienta para gestionar el desarrollo de tu proyecto.\n",
    "\n",
    "Accede al tablero del desaf√≠o\n",
    "Inicia sesi√≥n en tu cuenta de Trello y accede al tablero del desaf√≠o mediante el siguiente enlace:\n",
    "\n",
    "Challenge ONE Data Science ‚Äì Telecom X parte 2(https://trello.com/b/y1FQQnc7/telecomxparte2latam)\n",
    "\n",
    "### Creando tu copia de Trello\n",
    "Para comenzar a gestionar tu progreso, sigue estos pasos:\n",
    "\n",
    "Accede al tablero del desaf√≠o: Challenge ONE Data Science: Telecom X parte 2\n",
    "\n",
    "Crea un tablero a partir de este modelo:\n",
    "\n",
    "En la parte superior del tablero, haz clic en 'Crear tablero basado en plantilla' o, si lo prefieres, en los tres puntos en la parte superior y selecciona 'Copiar tablero'.\n",
    "\n",
    "Ahora tienes una copia del tablero, incluyendo listas, tarjetas y etiquetas. Utiliza esta estructura para aplicar la metodolog√≠a √°gil y seguir tu progreso moviendo las tarjetas a medida que avanzas en el desaf√≠o."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef1ea6b",
   "metadata": {},
   "source": [
    "##  03 Preparando el ambiente\n",
    "### Creaci√≥n de modelos predictivos\n",
    "Despu√©s de completar la etapa de ETL (Extract, Transform, Load) en la Parte 1 del desaf√≠o, es momento de utilizar los datos ya tratados para avanzar en la construcci√≥n de modelos predictivos.\n",
    "\n",
    "Para ello, aseg√∫rate de estar utilizando el conjunto de datos que ya limpiaste y transformaste anteriormente. Esta continuidad es fundamental para garantizar la consistencia de los an√°lisis y la eficacia de los modelos.\n",
    "\n",
    "En caso de que a√∫n no hayas extra√≠do los datos tratados de la Parte 1, puedes guardarlos en un archivo CSV con el siguiente comando:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf83a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.to_csv(\"datos_tratados.csv\", index=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea549876",
   "metadata": {},
   "source": [
    "Con este archivo, podr√°s cargar los datos ya listos para an√°lisis y modelado en esta segunda parte del desaf√≠o."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c6ddee",
   "metadata": {},
   "source": [
    "##  04 Para saber m√°s\n",
    "Este desaf√≠o fue dise√±ado para que puedas aplicar de manera pr√°ctica los conocimientos adquiridos en los siguientes cursos:\n",
    "\n",
    "* Curso Online Estad√≠stica con Python: frecuencias y medidas | Alura\n",
    "\n",
    "* Curso Online Estad√≠stica con Python: Probabilidad y muestreo | Alura\n",
    "\n",
    "* Curso Online Data Science: probando relaciones con regresi√≥n lineal | Alura\n",
    "\n",
    "* Curso Online Regresi√≥n Lineal: T√©cnicas Avanzadas de Modelado | Alura\n",
    "\n",
    "* Curso Online Clasificaci√≥n: aprendiendo a clasificar datos con Machine Learning | Alura\n",
    "\n",
    "* Curso Online Clasificaci√≥n: validaci√≥n de modelos y m√©tricas de evaluaci√≥n | Alura\n",
    "\n",
    "* Curso Online IA aumentada: previsi√≥n de atrasos de vuelos | Alura"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbcbd03",
   "metadata": {},
   "source": [
    "#  01 Suba su proyecto en GitHub\n",
    "Git y GitHub\n",
    "Git y GitHub son herramientas esenciales para cualquier analista de datos, ya que permiten el versionado y el intercambio eficiente de proyectos.\n",
    "\n",
    "En este desaf√≠o, deber√°s subir tu cuaderno de Colab a un repositorio en GitHub. Esto garantizar√° que tu progreso est√© guardado y accesible desde cualquier lugar.\n",
    "\n",
    "Lo que necesitas hacer:\n",
    "Crea un nuevo repositorio en GitHub para almacenar tu proyecto.\n",
    "\n",
    "Exporta tu cuaderno de Colab como un archivo .ipynb.\n",
    "\n",
    "Realiza el upload del cuaderno al repositorio.\n",
    "\n",
    "Mant√©n tu trabajo actualizado utilizando git pull, git add, git commit y git push cuando sea necesario.\n",
    "\n",
    "Si necesitas repasar conceptos, revisa los siguientes recursos:\n",
    "\n",
    "Git - Configurando Git por primera vez\n",
    "\n",
    "C√≥mo subir mi proyecto en GitHub\n",
    "\n",
    "C√≥mo escribir un README incre√≠ble en tu Github\n",
    "\n",
    "README\n",
    "El archivo README es esencial para documentar tu proyecto, explicando su prop√≥sito, funcionalidades e instrucciones de uso.\n",
    "\n",
    "Como desaf√≠o adicional, crea un archivo README.md para tu proyecto Telecom X - Parte 2, incluyendo:\n",
    "\n",
    "El prop√≥sito del an√°lisis realizado, destacando el objetivo principal: predecir el churn (cancelaci√≥n) de clientes en base a variables relevantes.\n",
    "\n",
    "Estructura del proyecto y organizaci√≥n de los archivos, como el cuaderno principal, los datos tratados en formato CSV y cualquier carpeta con visualizaciones.\n",
    "\n",
    "Descripci√≥n del proceso de preparaci√≥n de los datos, incluyendo:\n",
    "\n",
    "Clasificaci√≥n de las variables en categ√≥ricas y num√©ricas.\n",
    "\n",
    "Etapas de normalizaci√≥n o codificaci√≥n.\n",
    "\n",
    "Separaci√≥n de los datos en conjuntos de entrenamiento y prueba.\n",
    "\n",
    "Justificaciones para las decisiones tomadas durante la modelizaci√≥n.\n",
    "\n",
    "Ejemplos de gr√°ficos e insights obtenidos durante el an√°lisis exploratorio de datos (EDA).\n",
    "\n",
    "Instrucciones para ejecutar el cuaderno, incluyendo qu√© bibliotecas deben instalarse y c√≥mo cargar los datos tratados.\n",
    "\n",
    "Este README har√° que tu proyecto sea m√°s completo, organizado y f√°cil de entender, lo cual es un gran diferencial tanto en entornos acad√©micos como profesionales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52096c3e",
   "metadata": {},
   "source": [
    "##  02 Entrega del Challenge\n",
    "¬°Felicidades por completar tu challenge! Estamos seguros de que desarrollaste un proyecto incre√≠ble.\n",
    "\n",
    "¬°IMPORTANTE!\n",
    "Verifica la URL de tu proyecto antes de enviarlo.\n",
    "\n",
    "El sistema ACEPTA √öNICAMENTE URLs de GitHub.\n",
    "\n",
    "Debes enviar solo el enlace del repositorio GitHub de tu proyecto, preferiblemente sin deploy.\n",
    "\n",
    "Despu√©s de agregar la URL de tu proyecto, descarga la insignia que aparecer√° al hacer clic en el bot√≥n de env√≠o y, luego, env√≠a tu proyecto.\n",
    "\n",
    "Tienes 5 intentos para entregar tu proyecto.\n",
    "\n",
    "Despu√©s de la entrega del desaf√≠o, ¬°DEBES COMPLETAR EL CURSO Y GENERAR TU CERTIFICADO!\n",
    "Descarga tu insignia, comp√°rtela en LinkedIn y en todas tus redes sociales usando los hashtags #AluraLatam y #oraclenexteducation.\n",
    "\n",
    "No olvides revisar este video que preparamos para ti con el paso a paso descrito arriba."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e00c2d",
   "metadata": {},
   "source": [
    "#  03 Importancia del Desafio\n",
    "## Desaf√≠o Telecom X parte 2\n",
    "El Desaf√≠o Telecom X parte 2 ofrece una oportunidad √∫nica para aplicar conocimientos fundamentales de estad√≠stica, regresi√≥n lineal y machine learning, adem√°s de habilidades esenciales en ciencia de datos, en un escenario empresarial real.\n",
    "\n",
    "### Aplicaci√≥n pr√°ctica del conocimiento\n",
    "\n",
    "`En este desaf√≠o, pondr√°s en pr√°ctica conceptos fundamentales de estad√≠stica, esenciales para comprender el comportamiento de los datos y fundamentar decisiones anal√≠ticas.`\n",
    "\n",
    "`Uno de los pasos principales ser√° preparar y separar los datos de forma adecuada para la creaci√≥n de modelos predictivos, asegurando un equilibrio entre los datos de entrenamiento y prueba ‚Äî algo indispensable para construir modelos confiables.`\n",
    "\n",
    "`Al realizar el an√°lisis de correlaci√≥n entre variables, ser√° posible identificar qu√© factores influyen m√°s en la cancelaci√≥n de servicios (churn). Esto permitir√° aplicar la regresi√≥n lineal como herramienta para modelar estas relaciones y entender el impacto de cada variable en el comportamiento de los clientes.`\n",
    "\n",
    "`Con ello, construir√°s una base s√≥lida para el desarrollo de modelos de machine learning orientados a la predicci√≥n de churn, ayudando a la empresa a anticipar el riesgo de p√©rdida de clientes y tomar decisiones estrat√©gicas para reducir ese impacto.`\n",
    "\n",
    "`Este desaf√≠o no solo contribuye a tu crecimiento en el √°rea de Ciencia de Datos, sino que tambi√©n demuestra en la pr√°ctica c√≥mo la ciencia de datos puede utilizarse para resolver problemas reales enfrentados por empresas en el mercado.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967f5c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   customerID Churn                                           customer  \\\n",
      "0  0002-ORFBO    No  {'gender': 'Female', 'SeniorCitizen': 0, 'Part...   \n",
      "1  0003-MKNFE    No  {'gender': 'Male', 'SeniorCitizen': 0, 'Partne...   \n",
      "2  0004-TLHLJ   Yes  {'gender': 'Male', 'SeniorCitizen': 0, 'Partne...   \n",
      "3  0011-IGKFF   Yes  {'gender': 'Male', 'SeniorCitizen': 1, 'Partne...   \n",
      "4  0013-EXCHZ   Yes  {'gender': 'Female', 'SeniorCitizen': 1, 'Part...   \n",
      "\n",
      "                                             phone  \\\n",
      "0   {'PhoneService': 'Yes', 'MultipleLines': 'No'}   \n",
      "1  {'PhoneService': 'Yes', 'MultipleLines': 'Yes'}   \n",
      "2   {'PhoneService': 'Yes', 'MultipleLines': 'No'}   \n",
      "3   {'PhoneService': 'Yes', 'MultipleLines': 'No'}   \n",
      "4   {'PhoneService': 'Yes', 'MultipleLines': 'No'}   \n",
      "\n",
      "                                            internet  \\\n",
      "0  {'InternetService': 'DSL', 'OnlineSecurity': '...   \n",
      "1  {'InternetService': 'DSL', 'OnlineSecurity': '...   \n",
      "2  {'InternetService': 'Fiber optic', 'OnlineSecu...   \n",
      "3  {'InternetService': 'Fiber optic', 'OnlineSecu...   \n",
      "4  {'InternetService': 'Fiber optic', 'OnlineSecu...   \n",
      "\n",
      "                                             account  \n",
      "0  {'Contract': 'One year', 'PaperlessBilling': '...  \n",
      "1  {'Contract': 'Month-to-month', 'PaperlessBilli...  \n",
      "2  {'Contract': 'Month-to-month', 'PaperlessBilli...  \n",
      "3  {'Contract': 'Month-to-month', 'PaperlessBilli...  \n",
      "4  {'Contract': 'Month-to-month', 'PaperlessBilli...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Especifica la ruta a tu archivo JSON\n",
    "ruta_archivo = '../data/TelecomX_Data.json'\n",
    "\n",
    "# Abre el archivo JSON y carga los datos\n",
    "with open(ruta_archivo, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Como el JSON que mostraste parece ser una lista de diccionarios,\n",
    "# podemos directamente crear un DataFrame a partir de esa lista.\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Vamos a ver las primeras filas del DataFrame para verificar la extracci√≥n\n",
    "print(df.head())\n",
    "\n",
    "# Eliminar la columna 'customerID' si existe\n",
    "if 'customerID' in df.columns:\n",
    "    df = df.drop('customerID', axis=1)\n",
    "    print(\"Columna 'customerID' eliminada.\")\n",
    "else:\n",
    "    print(\"La columna 'customerID' no se encontr√≥ en el DataFrame.\")\n",
    "\n",
    "print(\"\\nColumnas restantes:\")\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12cf65fb",
   "metadata": {},
   "source": [
    "## Claude:\n",
    "# üöÄ Plan de Acci√≥n para la Predicci√≥n de Cancelaci√≥n (Churn)\n",
    "\n",
    "## 1. Preparaci√≥n de los Datos para el Modelado\n",
    "\n",
    "### Tratamiento de valores nulos\n",
    "- **Imputaci√≥n**: media, mediana, moda, regresi√≥n\n",
    "- **Eliminaci√≥n** de filas/columnas\n",
    "- **Algoritmos** que manejen valores faltantes\n",
    "\n",
    "### Tratamiento de valores at√≠picos (outliers)\n",
    "- **Eliminaci√≥n**\n",
    "- **Transformaci√≥n**\n",
    "- **Winsorizaci√≥n**\n",
    "\n",
    "### Codificaci√≥n de variables categ√≥ricas\n",
    "- **One-Hot Encoding**: variables nominales (sin orden intr√≠nseco)\n",
    "- **Label Encoding** u **Ordinal Encoding**: variables ordinales (con orden)\n",
    "\n",
    "### Normalizaci√≥n/Estandarizaci√≥n de variables num√©ricas\n",
    "- **Normalizaci√≥n (Min-Max Scaling)**: escala entre 0 y 1\n",
    "- **Estandarizaci√≥n (Standard Scaling)**: media 0 y desviaci√≥n est√°ndar 1\n",
    "\n",
    "### Creaci√≥n de nuevas caracter√≠sticas (Feature Engineering)\n",
    "- **Combinar** o **transformar** caracter√≠sticas existentes\n",
    "- Ejemplo: \"cargo mensual\" + \"meses de contrato\" = \"gasto total\"\n",
    "\n",
    "## 2. An√°lisis de Correlaci√≥n y Selecci√≥n de Variables\n",
    "\n",
    "### Matriz de correlaci√≥n\n",
    "- **Relaciones** entre variables num√©ricas\n",
    "- Identificar **multicolinealidad**\n",
    "\n",
    "### Selecci√≥n de variables (Feature Selection)\n",
    "- **M√©todos de filtro**: œá¬≤, ANOVA, Information Gain\n",
    "- **M√©todos de envoltura**: Recursive Feature Elimination (RFE)\n",
    "- **M√©todos incrustados**: Lasso/Ridge Regression, √°rboles de decisi√≥n\n",
    "\n",
    "### An√°lisis de la importancia de las caracter√≠sticas\n",
    "- **Feature Importance** en modelos basados en √°rboles\n",
    "\n",
    "## 3. Entrenamiento de Dos o M√°s Modelos de Clasificaci√≥n\n",
    "\n",
    "### Modelos recomendados para clasificaci√≥n binaria\n",
    "- **Regresi√≥n Log√≠stica**: interpretable y eficaz\n",
    "- **Random Forest** o **Gradient Boosting** (LightGBM/XGBoost)\n",
    "\n",
    "### Pasos clave\n",
    "- **Divisi√≥n de datos**: 70/30 o 80/20 (estratificada)\n",
    "- **Entrenamiento** con conjunto de entrenamiento\n",
    "- **Ajuste de hiperpar√°metros**: GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "## 4. Evaluaci√≥n del Rendimiento de los Modelos con M√©tricas\n",
    "\n",
    "### M√©tricas fundamentales para clases desbalanceadas\n",
    "- **Matriz de Confusi√≥n**: VP, VN, FP, FN\n",
    "- **Precisi√≥n (Precision)**: predicciones positivas correctas\n",
    "- **Recall (Sensibilidad)**: casos positivos reales identificados\n",
    "- **F1-Score**: media arm√≥nica de precisi√≥n y recall\n",
    "- **Curva ROC** y **AUC**: rendimiento general de clasificaci√≥n\n",
    "- **Curva Precision-Recall**: para conjuntos desbalanceados\n",
    "\n",
    "## 5. Interpretaci√≥n de los Resultados\n",
    "\n",
    "### Importancia de las caracter√≠sticas\n",
    "- **M√©todos intr√≠nsecos**: feature_importances_ en √°rboles\n",
    "- **T√©cnicas post-hoc**: SHAP, LIME\n",
    "\n",
    "### An√°lisis de coeficientes\n",
    "- **Regresi√≥n Log√≠stica**: interpretar direcci√≥n y magnitud del impacto\n",
    "\n",
    "## 6. Creaci√≥n de una Conclusi√≥n Estrat√©gica\n",
    "\n",
    "### Principales factores que influyen en la cancelaci√≥n\n",
    "- Identificar **3-5 variables** m√°s importantes\n",
    "\n",
    "### Recomendaciones estrat√©gicas\n",
    "- **Duraci√≥n del contrato**: incentivos por contratos largos\n",
    "- **Tipos de servicios**: revisar ofertas problem√°ticas\n",
    "- **Cargos mensuales**: planes alternativos o paquetes\n",
    "\n",
    "### Limitaciones del modelo y pr√≥ximos pasos\n",
    "- **Transparencia** sobre limitaciones\n",
    "- **Futuras mejoras**: m√°s modelos, feature engineering, nuevos datos\n",
    "\n",
    "---\n",
    "\n",
    "**Palabras clave destacadas**: preparaci√≥n de datos, tratamiento de valores nulos, outliers, codificaci√≥n, normalizaci√≥n, feature engineering, correlaci√≥n, selecci√≥n de variables, clasificaci√≥n binaria, regresi√≥n log√≠stica, random forest, gradient boosting, m√©tricas de evaluaci√≥n, matriz de confusi√≥n, precisi√≥n, recall, F1-score, ROC, AUC, interpretaci√≥n, importancia de caracter√≠sticas, conclusi√≥n estrat√©gica."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7914425",
   "metadata": {},
   "source": [
    "# Prompt con los datos de Trello:\n",
    "# üöÄ Desaf√≠o TelecomX - Predicci√≥n de Cancelaci√≥n de Clientes (Churn)\n",
    "\n",
    "## Objetivo Principal\n",
    "Desarrollar modelos de Machine Learning para predecir la cancelaci√≥n de clientes en TelecomX, identificando los factores m√°s influyentes y proponiendo estrategias de retenci√≥n.\n",
    "\n",
    "---\n",
    "\n",
    "## üìã Parte 1: Preparaci√≥n y Carga de Datos\n",
    "\n",
    "### 1.1 Carga del Dataset\n",
    "**Descripci√≥n:** Carga el archivo CSV que contiene los datos tratados anteriormente.\n",
    "\n",
    "**Instrucciones:**\n",
    "- Utiliza el mismo archivo que limpiaste y organizaste en la Parte 1 del desaf√≠o TelecomX\n",
    "- Debe contener solo las columnas relevantes, ya con los datos corregidos y estandarizados\n",
    "- C√≥digo de referencia disponible:\n",
    "```python\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Especifica la ruta a tu archivo JSON\n",
    "ruta_archivo = '../data/TelecomX_Data.json'\n",
    "\n",
    "# Abre el archivo JSON y carga los datos\n",
    "with open(ruta_archivo, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Crear DataFrame a partir de la lista de diccionarios\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Verificar la extracci√≥n\n",
    "print(df.head())\n",
    "```\n",
    "\n",
    "### 1.2 Limpieza de Columnas\n",
    "**Descripci√≥n:** Elimina columnas que no aportan valor al an√°lisis o a los modelos predictivos.\n",
    "\n",
    "**Instrucciones:**\n",
    "- Eliminar identificadores √∫nicos (por ejemplo, ID del cliente)\n",
    "- Remover columnas que no ayudan en la predicci√≥n de cancelaci√≥n\n",
    "- Estas columnas pueden perjudicar el desempe√±o de los modelos\n",
    "\n",
    "---\n",
    "\n",
    "## üîß Parte 2: Preprocesamiento de Datos\n",
    "\n",
    "### 2.1 Codificaci√≥n de Variables Categ√≥ricas\n",
    "**Descripci√≥n:** Transforma las variables categ√≥ricas a formato num√©rico para hacerlas compatibles con los algoritmos de machine learning.\n",
    "\n",
    "**Instrucciones:**\n",
    "- Utiliza un m√©todo de codificaci√≥n adecuado como **one-hot encoding**\n",
    "- Considera usar `get_dummies()` o `OneHotEncoder`\n",
    "\n",
    "üí° **Sugerencia:** Consulta documentaci√≥n sobre cu√°ndo usar get_dummies o OneHotEncoder\n",
    "\n",
    "### 2.2 An√°lisis de Balance de Clases\n",
    "**Descripci√≥n:** Calcula la proporci√≥n de clientes que cancelaron en relaci√≥n con los que permanecieron activos.\n",
    "\n",
    "**Instrucciones:**\n",
    "- Eval√∫a si existe un desbalance entre las clases\n",
    "- Esto puede impactar en los modelos predictivos y en el an√°lisis de resultados\n",
    "- Usa `value_counts()` de pandas para obtener esta proporci√≥n\n",
    "\n",
    "üí° **Sugerencia:** Consulta la documentaci√≥n oficial de value_counts()\n",
    "\n",
    "### 2.3 T√©cnicas de Balanceo (Opcional)\n",
    "**Descripci√≥n:** Si deseas profundizar en el an√°lisis, aplica t√©cnicas de balanceo como undersampling o oversampling.\n",
    "\n",
    "**Instrucciones:**\n",
    "- En situaciones de fuerte desbalanceo, herramientas como **SMOTE** pueden ser √∫tiles\n",
    "- Generar ejemplos sint√©ticos de la clase minoritaria\n",
    "\n",
    "üí° **Sugerencia:** Lee sobre manejo de desbalanceo de clases en recursos especializados\n",
    "\n",
    "### 2.4 Normalizaci√≥n y Estandarizaci√≥n\n",
    "**Descripci√≥n:** Eval√∫a la necesidad de normalizar o estandarizar los datos, seg√∫n los modelos que se aplicar√°n.\n",
    "\n",
    "**Instrucciones:**\n",
    "- **Modelos que REQUIEREN normalizaci√≥n:** KNN, SVM, Regresi√≥n Log√≠stica, Redes Neuronales\n",
    "- **Modelos que NO requieren normalizaci√≥n:** Decision Tree, Random Forest, XGBoost\n",
    "- Aplicar seg√∫n el tipo de modelo seleccionado\n",
    "\n",
    "üí° **Sugerencia:** Consulta art√≠culos sobre normalizaci√≥n y estandarizaci√≥n en Machine Learning\n",
    "\n",
    "---\n",
    "\n",
    "## üìä Parte 3: An√°lisis Exploratorio y Correlaciones\n",
    "\n",
    "### 3.1 Matriz de Correlaci√≥n\n",
    "**Descripci√≥n:** Visualiza la matriz de correlaci√≥n para identificar relaciones entre las variables num√©ricas.\n",
    "\n",
    "**Instrucciones:**\n",
    "- Identificar relaciones entre variables num√©ricas\n",
    "- Prestar especial atenci√≥n a variables con mayor correlaci√≥n con la cancelaci√≥n\n",
    "- Estas pueden ser fuertes candidatas para el modelo predictivo\n",
    "\n",
    "### 3.2 An√°lisis de Variables Espec√≠ficas\n",
    "**Descripci√≥n:** Investiga c√≥mo variables espec√≠ficas se relacionan con la cancelaci√≥n.\n",
    "\n",
    "**Variables a analizar:**\n",
    "- **Tiempo de contrato √ó Cancelaci√≥n**\n",
    "- **Gasto total √ó Cancelaci√≥n**\n",
    "\n",
    "**Instrucciones:**\n",
    "- Utiliza gr√°ficos como **boxplots** o **scatter plots**\n",
    "- Visualizar patrones y posibles tendencias\n",
    "- Identificar insights relevantes para el negocio\n",
    "\n",
    "---\n",
    "\n",
    "## ü§ñ Parte 4: Desarrollo de Modelos\n",
    "\n",
    "### 4.1 Divisi√≥n del Dataset\n",
    "**Descripci√≥n:** Divide el conjunto de datos en entrenamiento y prueba para evaluar el rendimiento del modelo.\n",
    "\n",
    "**Instrucciones:**\n",
    "- Divisi√≥n com√∫n: **70% entrenamiento / 30% prueba** o **80/20**\n",
    "- Depende del tama√±o de la base de datos\n",
    "- Usar estratificaci√≥n si hay desbalance de clases\n",
    "\n",
    "### 4.2 Creaci√≥n de Modelos\n",
    "**Descripci√≥n:** Crea al menos dos modelos diferentes para predecir la cancelaci√≥n de clientes.\n",
    "\n",
    "**Modelos recomendados:**\n",
    "1. **Modelo que requiere normalizaci√≥n:** Regresi√≥n Log√≠stica o KNN\n",
    "2. **Modelo que no requiere normalizaci√≥n:** √Årbol de Decisi√≥n o Random Forest\n",
    "\n",
    "**Justificaci√≥n:**\n",
    "- **Regresi√≥n Log√≠stica / KNN:** Sensibles a la escala de los datos, normalizaci√≥n importante\n",
    "- **√Årbol de Decisi√≥n / Random Forest:** No dependen de la escala de los datos\n",
    "\n",
    "üí° **Nota:** La decisi√≥n de aplicar o no la normalizaci√≥n depende de los modelos seleccionados\n",
    "\n",
    "---\n",
    "\n",
    "## üìà Parte 5: Evaluaci√≥n y Comparaci√≥n de Modelos\n",
    "\n",
    "### 5.1 M√©tricas de Evaluaci√≥n\n",
    "**Descripci√≥n:** Eval√∫a cada modelo utilizando las siguientes m√©tricas.\n",
    "\n",
    "**M√©tricas obligatorias:**\n",
    "- **Exactitud (Accuracy)**\n",
    "- **Precisi√≥n (Precision)**\n",
    "- **Recall (Sensibilidad)**\n",
    "- **F1-score**\n",
    "- **Matriz de confusi√≥n**\n",
    "\n",
    "### 5.2 An√°lisis Cr√≠tico y Comparaci√≥n\n",
    "**Descripci√≥n:** Realiza un an√°lisis cr√≠tico y compara los modelos.\n",
    "\n",
    "**Preguntas clave:**\n",
    "- ¬øCu√°l modelo tuvo el mejor desempe√±o?\n",
    "- ¬øAlg√∫n modelo present√≥ overfitting o underfitting?\n",
    "\n",
    "**Definiciones:**\n",
    "- **Overfitting:** El modelo aprende demasiado sobre los datos de entrenamiento, perdiendo capacidad de generalizar\n",
    "  - *Soluci√≥n:* Reducir complejidad del modelo o aumentar datos de entrenamiento\n",
    "- **Underfitting:** El modelo no captura bien las tendencias de los datos, es demasiado simple\n",
    "  - *Soluci√≥n:* Aumentar complejidad del modelo o ajustar par√°metros\n",
    "\n",
    "---\n",
    "\n",
    "## üîç Parte 6: An√°lisis de Importancia de Variables\n",
    "\n",
    "### 6.1 Interpretaci√≥n por Tipo de Modelo\n",
    "**Descripci√≥n:** Despu√©s de elegir los modelos, realiza el an√°lisis de las variables m√°s relevantes para la predicci√≥n de cancelaci√≥n.\n",
    "\n",
    "**Por tipo de modelo:**\n",
    "\n",
    "- **Regresi√≥n Log√≠stica:** Investigar los coeficientes de las variables\n",
    "- **KNN:** Observar c√≥mo los vecinos m√°s cercanos influyen en la clasificaci√≥n\n",
    "- **Random Forest:** Utilizar la importancia de variables proporcionada por el modelo\n",
    "- **SVM:** Analizar los coeficientes de los vectores de soporte\n",
    "- **Otros Modelos:** Considerar m√©tricas espec√≠ficas (coeficientes en modelos lineales, pesos en redes neuronales, importancia en t√©cnicas de boosting)\n",
    "\n",
    "---\n",
    "\n",
    "## üìã Parte 7: Informe Final y Recomendaciones\n",
    "\n",
    "### 7.1 Informe Detallado\n",
    "**Descripci√≥n:** Elabora un informe detallado, destacando los factores que m√°s influyen en la cancelaci√≥n.\n",
    "\n",
    "**Incluir:**\n",
    "- Factores m√°s influyentes basados en las variables seleccionadas\n",
    "- Rendimiento de cada modelo\n",
    "- Comparaci√≥n entre modelos\n",
    "- Limitaciones y posibles mejoras\n",
    "\n",
    "### 7.2 Estrategias de Retenci√≥n\n",
    "**Descripci√≥n:** Identifica los principales factores que afectan la cancelaci√≥n de clientes y propone estrategias de retenci√≥n.\n",
    "\n",
    "**Deliverables:**\n",
    "- Principales factores de cancelaci√≥n\n",
    "- Estrategias de retenci√≥n basadas en los resultados\n",
    "- Recomendaciones accionables para el negocio\n",
    "- Pr√≥ximos pasos y mejoras futuras\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Criterios de √âxito\n",
    "\n",
    "- **Preparaci√≥n de datos:** Limpieza, codificaci√≥n y normalizaci√≥n correctas\n",
    "- **An√°lisis exploratorio:** Insights relevantes sobre correlaciones y patrones\n",
    "- **Modelado:** Al menos 2 modelos diferentes con justificaci√≥n t√©cnica\n",
    "- **Evaluaci√≥n:** Uso correcto de m√©tricas y an√°lisis cr√≠tico\n",
    "- **Interpretaci√≥n:** Identificaci√≥n clara de variables m√°s importantes\n",
    "- **Conclusiones:** Recomendaciones estrat√©gicas basadas en evidencia\n",
    "\n",
    "---\n",
    "\n",
    "## üìö Recursos Adicionales\n",
    "\n",
    "- Documentaci√≥n de pandas para manipulaci√≥n de datos\n",
    "- Scikit-learn para modelos de Machine Learning\n",
    "- Matplotlib/Seaborn para visualizaciones\n",
    "- Art√≠culos especializados en desbalanceo de clases y normalizaci√≥n\n",
    "- Gu√≠as de interpretaci√≥n de modelos de ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ff0fba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   customerID Churn                                           customer  \\\n",
      "0  0002-ORFBO    No  {'gender': 'Female', 'SeniorCitizen': 0, 'Part...   \n",
      "1  0003-MKNFE    No  {'gender': 'Male', 'SeniorCitizen': 0, 'Partne...   \n",
      "2  0004-TLHLJ   Yes  {'gender': 'Male', 'SeniorCitizen': 0, 'Partne...   \n",
      "3  0011-IGKFF   Yes  {'gender': 'Male', 'SeniorCitizen': 1, 'Partne...   \n",
      "4  0013-EXCHZ   Yes  {'gender': 'Female', 'SeniorCitizen': 1, 'Part...   \n",
      "\n",
      "                                             phone  \\\n",
      "0   {'PhoneService': 'Yes', 'MultipleLines': 'No'}   \n",
      "1  {'PhoneService': 'Yes', 'MultipleLines': 'Yes'}   \n",
      "2   {'PhoneService': 'Yes', 'MultipleLines': 'No'}   \n",
      "3   {'PhoneService': 'Yes', 'MultipleLines': 'No'}   \n",
      "4   {'PhoneService': 'Yes', 'MultipleLines': 'No'}   \n",
      "\n",
      "                                            internet  \\\n",
      "0  {'InternetService': 'DSL', 'OnlineSecurity': '...   \n",
      "1  {'InternetService': 'DSL', 'OnlineSecurity': '...   \n",
      "2  {'InternetService': 'Fiber optic', 'OnlineSecu...   \n",
      "3  {'InternetService': 'Fiber optic', 'OnlineSecu...   \n",
      "4  {'InternetService': 'Fiber optic', 'OnlineSecu...   \n",
      "\n",
      "                                             account  \n",
      "0  {'Contract': 'One year', 'PaperlessBilling': '...  \n",
      "1  {'Contract': 'Month-to-month', 'PaperlessBilli...  \n",
      "2  {'Contract': 'Month-to-month', 'PaperlessBilli...  \n",
      "3  {'Contract': 'Month-to-month', 'PaperlessBilli...  \n",
      "4  {'Contract': 'Month-to-month', 'PaperlessBilli...  \n",
      "Columna 'customerID' eliminada.\n",
      "\n",
      "Columnas restantes:\n",
      "Index(['Churn', 'customer', 'phone', 'internet', 'account'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Especifica la ruta a tu archivo JSON\n",
    "ruta_archivo = '../data/TelecomX_Data.json'\n",
    "\n",
    "# Abre el archivo JSON y carga los datos\n",
    "with open(ruta_archivo, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Como el JSON que mostraste parece ser una lista de diccionarios,\n",
    "# podemos directamente crear un DataFrame a partir de esa lista.\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Vamos a ver las primeras filas del DataFrame para verificar la extracci√≥n\n",
    "print(df.head())\n",
    "\n",
    "# Eliminar la columna 'customerID' si existe\n",
    "if 'customerID' in df.columns:\n",
    "    df = df.drop('customerID', axis=1)\n",
    "    print(\"Columna 'customerID' eliminada.\")\n",
    "else:\n",
    "    print(\"La columna 'customerID' no se encontr√≥ en el DataFrame.\")\n",
    "\n",
    "print(\"\\nColumnas restantes:\")\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d14b6d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame despu√©s de aplanar todas las columnas anidadas:\n",
      "  Churn  gender  SeniorCitizen Partner Dependents  tenure PhoneService  \\\n",
      "0    No  Female              0     Yes        Yes       9          Yes   \n",
      "1    No    Male              0      No         No       9          Yes   \n",
      "2   Yes    Male              0      No         No       4          Yes   \n",
      "3   Yes    Male              1     Yes         No      13          Yes   \n",
      "4   Yes  Female              1     Yes         No       3          Yes   \n",
      "\n",
      "  MultipleLines InternetService OnlineSecurity OnlineBackup DeviceProtection  \\\n",
      "0            No             DSL             No          Yes               No   \n",
      "1           Yes             DSL             No           No               No   \n",
      "2            No     Fiber optic             No           No              Yes   \n",
      "3            No     Fiber optic             No          Yes              Yes   \n",
      "4            No     Fiber optic             No           No               No   \n",
      "\n",
      "  TechSupport StreamingTV StreamingMovies        Contract PaperlessBilling  \\\n",
      "0         Yes         Yes              No        One year              Yes   \n",
      "1          No          No             Yes  Month-to-month               No   \n",
      "2          No          No              No  Month-to-month              Yes   \n",
      "3          No         Yes             Yes  Month-to-month              Yes   \n",
      "4         Yes         Yes              No  Month-to-month              Yes   \n",
      "\n",
      "      PaymentMethod  Charges.Monthly Charges.Total  \n",
      "0      Mailed check             65.6         593.3  \n",
      "1      Mailed check             59.9         542.4  \n",
      "2  Electronic check             73.9        280.85  \n",
      "3  Electronic check             98.0       1237.85  \n",
      "4      Mailed check             83.9         267.4  \n",
      "\n",
      "N√∫mero de columnas despu√©s de aplanar: 20\n",
      "\n",
      "Tipos de datos actuales de las columnas:\n",
      "Churn                object\n",
      "gender               object\n",
      "SeniorCitizen         int64\n",
      "Partner              object\n",
      "Dependents           object\n",
      "tenure                int64\n",
      "PhoneService         object\n",
      "MultipleLines        object\n",
      "InternetService      object\n",
      "OnlineSecurity       object\n",
      "OnlineBackup         object\n",
      "DeviceProtection     object\n",
      "TechSupport          object\n",
      "StreamingTV          object\n",
      "StreamingMovies      object\n",
      "Contract             object\n",
      "PaperlessBilling     object\n",
      "PaymentMethod        object\n",
      "Charges.Monthly     float64\n",
      "Charges.Total        object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Aplanar la columna 'customer'\n",
    "customer_df = pd.json_normalize(df['customer'])\n",
    "df = pd.concat([df.drop('customer', axis=1), customer_df], axis=1)\n",
    "\n",
    "# Aplanar la columna 'phone'\n",
    "phone_df = pd.json_normalize(df['phone'])\n",
    "df = pd.concat([df.drop('phone', axis=1), phone_df], axis=1)\n",
    "\n",
    "# Aplanar la columna 'internet'\n",
    "internet_df = pd.json_normalize(df['internet'])\n",
    "df = pd.concat([df.drop('internet', axis=1), internet_df], axis=1)\n",
    "\n",
    "# Aplanar la columna 'account'\n",
    "account_df = pd.json_normalize(df['account'])\n",
    "df = pd.concat([df.drop('account', axis=1), account_df], axis=1)\n",
    "\n",
    "print(\"DataFrame despu√©s de aplanar todas las columnas anidadas:\")\n",
    "print(df.head())\n",
    "print(f\"\\nN√∫mero de columnas despu√©s de aplanar: {df.shape[1]}\")\n",
    "print(\"\\nTipos de datos actuales de las columnas:\")\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32a9502",
   "metadata": {},
   "source": [
    "## üßπ Limpieza y Conversi√≥n de Charges.Total\n",
    "Vamos a inspeccionar y corregir la columna Charges.Total. Es com√∫n que los valores vac√≠os o no num√©ricos en esta columna representen clientes nuevos que a√∫n no han acumulado cargos totales. En estos casos, suelen ser cero o un valor peque√±o.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac777570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores √∫nicos en 'Charges.Total' antes de la conversi√≥n (primeros 20):\n",
      "['593.3' '542.4' '280.85' '1237.85' '267.4' '571.45' '7904.25' '5377.8'\n",
      " '340.35' '5957.9' '2460.55' '8456.75' '351.5' '7261.25' '2560.1' '6849.4'\n",
      " '1993.2' '72.1' '2791.5' '25.1']\n",
      "\n",
      "N√∫mero de valores NaN en 'Charges.Total' despu√©s de la conversi√≥n: 11\n",
      "Tipo de dato de 'Charges.Total' despu√©s de la limpieza: float64\n",
      "\n",
      "Primeras filas del DataFrame con 'Charges.Total' limpio:\n",
      "  Churn  gender  SeniorCitizen Partner Dependents  tenure PhoneService  \\\n",
      "0    No  Female              0     Yes        Yes       9          Yes   \n",
      "1    No    Male              0      No         No       9          Yes   \n",
      "2   Yes    Male              0      No         No       4          Yes   \n",
      "3   Yes    Male              1     Yes         No      13          Yes   \n",
      "4   Yes  Female              1     Yes         No       3          Yes   \n",
      "\n",
      "  MultipleLines InternetService OnlineSecurity OnlineBackup DeviceProtection  \\\n",
      "0            No             DSL             No          Yes               No   \n",
      "1           Yes             DSL             No           No               No   \n",
      "2            No     Fiber optic             No           No              Yes   \n",
      "3            No     Fiber optic             No          Yes              Yes   \n",
      "4            No     Fiber optic             No           No               No   \n",
      "\n",
      "  TechSupport StreamingTV StreamingMovies        Contract PaperlessBilling  \\\n",
      "0         Yes         Yes              No        One year              Yes   \n",
      "1          No          No             Yes  Month-to-month               No   \n",
      "2          No          No              No  Month-to-month              Yes   \n",
      "3          No         Yes             Yes  Month-to-month              Yes   \n",
      "4         Yes         Yes              No  Month-to-month              Yes   \n",
      "\n",
      "      PaymentMethod  Charges.Monthly  Charges.Total  \n",
      "0      Mailed check             65.6         593.30  \n",
      "1      Mailed check             59.9         542.40  \n",
      "2  Electronic check             73.9         280.85  \n",
      "3  Electronic check             98.0        1237.85  \n",
      "4      Mailed check             83.9         267.40  \n"
     ]
    }
   ],
   "source": [
    "# Inspeccionar valores √∫nicos en Charges.Total para entender el problema\n",
    "print(\"Valores √∫nicos en 'Charges.Total' antes de la conversi√≥n (primeros 20):\")\n",
    "print(df['Charges.Total'].unique()[:20])\n",
    "\n",
    "# Reemplazar espacios vac√≠os o ' ' con NaN y luego convertir a num√©rico\n",
    "# El argumento errors='coerce' convertir√° cualquier valor no num√©rico en NaN\n",
    "df['Charges.Total'] = pd.to_numeric(df['Charges.Total'], errors='coerce')\n",
    "\n",
    "# Verificar si hay valores NaN despu√©s de la conversi√≥n\n",
    "print(f\"\\nN√∫mero de valores NaN en 'Charges.Total' despu√©s de la conversi√≥n: {df['Charges.Total'].isnull().sum()}\")\n",
    "\n",
    "# Llenar los valores NaN (por ejemplo, con 0, la media, o la mediana).\n",
    "# Para cargos totales, es razonable asumir 0 para nuevos clientes sin cargos registrados.\n",
    "df['Charges.Total'] = df['Charges.Total'].fillna(0) # Opcional: df['Charges.Total'].mean() para la media\n",
    "\n",
    "# Verificar el tipo de dato despu√©s de la limpieza\n",
    "print(f\"Tipo de dato de 'Charges.Total' despu√©s de la limpieza: {df['Charges.Total'].dtype}\")\n",
    "\n",
    "print(\"\\nPrimeras filas del DataFrame con 'Charges.Total' limpio:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccad6697",
   "metadata": {},
   "source": [
    "## üîÑ Codificaci√≥n de Variables Categ√≥ricas\n",
    "En este paso, transformaremos todas las columnas de tipo object (que son categ√≥ricas) en un formato num√©rico que los algoritmos de Machine Learning puedan entender. Usaremos pd.get_dummies para aplicar One-Hot Encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a9b320c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Columnas categ√≥ricas a codificar: ['gender', 'Partner', 'Dependents', 'PhoneService', 'MultipleLines', 'InternetService', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies', 'Contract', 'PaperlessBilling', 'PaymentMethod']\n",
      "\n",
      "DataFrame despu√©s de One-Hot Encoding:\n",
      "  Churn  SeniorCitizen  tenure  Charges.Monthly  Charges.Total  gender_Male  \\\n",
      "0    No              0       9             65.6         593.30            0   \n",
      "1    No              0       9             59.9         542.40            1   \n",
      "2   Yes              0       4             73.9         280.85            1   \n",
      "3   Yes              1      13             98.0        1237.85            1   \n",
      "4   Yes              1       3             83.9         267.40            0   \n",
      "\n",
      "   Partner_Yes  Dependents_Yes  PhoneService_Yes  \\\n",
      "0            1               1                 1   \n",
      "1            0               0                 1   \n",
      "2            0               0                 1   \n",
      "3            1               0                 1   \n",
      "4            1               0                 1   \n",
      "\n",
      "   MultipleLines_No phone service  ...  StreamingTV_No internet service  \\\n",
      "0                               0  ...                                0   \n",
      "1                               0  ...                                0   \n",
      "2                               0  ...                                0   \n",
      "3                               0  ...                                0   \n",
      "4                               0  ...                                0   \n",
      "\n",
      "   StreamingTV_Yes  StreamingMovies_No internet service  StreamingMovies_Yes  \\\n",
      "0                1                                    0                    0   \n",
      "1                0                                    0                    1   \n",
      "2                0                                    0                    0   \n",
      "3                1                                    0                    1   \n",
      "4                1                                    0                    0   \n",
      "\n",
      "   Contract_One year  Contract_Two year  PaperlessBilling_Yes  \\\n",
      "0                  1                  0                     1   \n",
      "1                  0                  0                     0   \n",
      "2                  0                  0                     1   \n",
      "3                  0                  0                     1   \n",
      "4                  0                  0                     1   \n",
      "\n",
      "   PaymentMethod_Credit card (automatic)  PaymentMethod_Electronic check  \\\n",
      "0                                      0                               0   \n",
      "1                                      0                               0   \n",
      "2                                      0                               1   \n",
      "3                                      0                               1   \n",
      "4                                      0                               0   \n",
      "\n",
      "   PaymentMethod_Mailed check  \n",
      "0                           1  \n",
      "1                           1  \n",
      "2                           0  \n",
      "3                           0  \n",
      "4                           1  \n",
      "\n",
      "[5 rows x 31 columns]\n",
      "\n",
      "N√∫mero de columnas despu√©s de encoding: 31\n",
      "\n",
      "Tipos de datos de las columnas despu√©s de encoding:\n",
      "uint8      26\n",
      "int64       2\n",
      "float64     2\n",
      "object      1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Identificar columnas categ√≥ricas (tipo 'object')\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Excluir la columna objetivo 'Churn' si est√° en las categ√≥ricas para no encodificarla a√∫n\n",
    "if 'Churn' in categorical_cols:\n",
    "    categorical_cols.remove('Churn')\n",
    "\n",
    "print(f\"\\nColumnas categ√≥ricas a codificar: {categorical_cols}\")\n",
    "\n",
    "# Aplicar One-Hot Encoding\n",
    "# drop_first=True evita la trampa de las variables dummy (multicolinealidad)\n",
    "df = pd.get_dummies(df, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "print(\"\\nDataFrame despu√©s de One-Hot Encoding:\")\n",
    "print(df.head())\n",
    "print(f\"\\nN√∫mero de columnas despu√©s de encoding: {df.shape[1]}\")\n",
    "print(\"\\nTipos de datos de las columnas despu√©s de encoding:\")\n",
    "# Esto nos dar√° un resumen de cu√°ntas columnas hay por cada tipo de dato\n",
    "print(df.dtypes.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c9e347",
   "metadata": {},
   "source": [
    "## ¬°Genial! Has completado exitosamente la codificaci√≥n de todas las variables categ√≥ricas. Tu DataFrame ahora est√° casi listo para el modelado, con todas las caracter√≠sticas en formato num√©rico, a excepci√≥n de la columna Churn que sigue siendo object.\n",
    "\n",
    "Ahora, vamos a realizar el an√°lisis de desbalanceo de clases y, crucialmente, convertir la columna Churn a un formato num√©rico (0 y 1) para que tus modelos de Machine Learning puedan procesarla.\n",
    "\n",
    "### üìä An√°lisis de Desbalanceo de Clases y Conversi√≥n de 'Churn'\n",
    "Evaluar la proporci√≥n de clientes que cancelaron versus los que no es fundamental, ya que un desbalanceo significativo puede sesgar tus modelos. Adem√°s, transformaremos \"Yes\"/\"No\" en 1/0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00f1b09f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conteo de clientes por estado de Churn:\n",
      "No     5174\n",
      "Yes    1869\n",
      "        224\n",
      "Name: Churn, dtype: int64\n",
      "\n",
      "Proporci√≥n de Churn:\n",
      "No Churn: 71.20%\n",
      "Churn: 25.72%\n",
      "\n",
      "Proporci√≥n num√©rica de Churn (0=No, 1=Yes):\n",
      "0.0    0.73463\n",
      "1.0    0.26537\n",
      "Name: Churn, dtype: float64\n",
      "\n",
      "¬°Advertencia! Existe un **desbalanceo significativo** en las clases de Churn.\n",
      "Considera aplicar t√©cnicas de balanceo como **SMOTE** si los modelos iniciales no rinden bien, especialmente en m√©tricas como Recall para la clase 'Churn'.\n",
      "\n",
      "Primeras filas del DataFrame con 'Churn' convertido a num√©rico:\n",
      "   Churn  SeniorCitizen  tenure  Charges.Monthly  Charges.Total  gender_Male  \\\n",
      "0    0.0              0       9             65.6         593.30            0   \n",
      "1    0.0              0       9             59.9         542.40            1   \n",
      "2    1.0              0       4             73.9         280.85            1   \n",
      "3    1.0              1      13             98.0        1237.85            1   \n",
      "4    1.0              1       3             83.9         267.40            0   \n",
      "\n",
      "   Partner_Yes  Dependents_Yes  PhoneService_Yes  \\\n",
      "0            1               1                 1   \n",
      "1            0               0                 1   \n",
      "2            0               0                 1   \n",
      "3            1               0                 1   \n",
      "4            1               0                 1   \n",
      "\n",
      "   MultipleLines_No phone service  ...  StreamingTV_No internet service  \\\n",
      "0                               0  ...                                0   \n",
      "1                               0  ...                                0   \n",
      "2                               0  ...                                0   \n",
      "3                               0  ...                                0   \n",
      "4                               0  ...                                0   \n",
      "\n",
      "   StreamingTV_Yes  StreamingMovies_No internet service  StreamingMovies_Yes  \\\n",
      "0                1                                    0                    0   \n",
      "1                0                                    0                    1   \n",
      "2                0                                    0                    0   \n",
      "3                1                                    0                    1   \n",
      "4                1                                    0                    0   \n",
      "\n",
      "   Contract_One year  Contract_Two year  PaperlessBilling_Yes  \\\n",
      "0                  1                  0                     1   \n",
      "1                  0                  0                     0   \n",
      "2                  0                  0                     1   \n",
      "3                  0                  0                     1   \n",
      "4                  0                  0                     1   \n",
      "\n",
      "   PaymentMethod_Credit card (automatic)  PaymentMethod_Electronic check  \\\n",
      "0                                      0                               0   \n",
      "1                                      0                               0   \n",
      "2                                      0                               1   \n",
      "3                                      0                               1   \n",
      "4                                      0                               0   \n",
      "\n",
      "   PaymentMethod_Mailed check  \n",
      "0                           1  \n",
      "1                           1  \n",
      "2                           0  \n",
      "3                           0  \n",
      "4                           1  \n",
      "\n",
      "[5 rows x 31 columns]\n",
      "\n",
      "Tipo de dato de 'Churn' despu√©s de la conversi√≥n: float64\n"
     ]
    }
   ],
   "source": [
    "# Calcular la proporci√≥n de la clase 'Churn'\n",
    "churn_counts = df['Churn'].value_counts()\n",
    "total_customers = df.shape[0]\n",
    "\n",
    "print(\"Conteo de clientes por estado de Churn:\")\n",
    "print(churn_counts)\n",
    "\n",
    "print(\"\\nProporci√≥n de Churn:\")\n",
    "print(f\"No Churn: {churn_counts.get('No', 0) / total_customers:.2%}\")\n",
    "print(f\"Churn: {churn_counts.get('Yes', 0) / total_customers:.2%}\")\n",
    "\n",
    "# Convertir la columna 'Churn' a formato num√©rico (0 y 1)\n",
    "# Asumiendo 'Yes' para Churn (1) y 'No' para No Churn (0)\n",
    "df['Churn'] = df['Churn'].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "print(\"\\nProporci√≥n num√©rica de Churn (0=No, 1=Yes):\")\n",
    "print(df['Churn'].value_counts(normalize=True))\n",
    "\n",
    "if churn_counts.get('Yes', 0) / total_customers < 0.3 or churn_counts.get('Yes', 0) / total_customers > 0.7:\n",
    "    print(\"\\n¬°Advertencia! Existe un **desbalanceo significativo** en las clases de Churn.\")\n",
    "    print(\"Considera aplicar t√©cnicas de balanceo como **SMOTE** si los modelos iniciales no rinden bien, especialmente en m√©tricas como Recall para la clase 'Churn'.\")\n",
    "else:\n",
    "    print(\"\\nLas clases de Churn parecen estar razonablemente balanceadas.\")\n",
    "\n",
    "print(\"\\nPrimeras filas del DataFrame con 'Churn' convertido a num√©rico:\")\n",
    "print(df.head())\n",
    "print(f\"\\nTipo de dato de 'Churn' despu√©s de la conversi√≥n: {df['Churn'].dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb14991",
   "metadata": {},
   "source": [
    "¬°Excelente! La columna Churn ha sido correctamente convertida a un tipo num√©rico (float64), con 1 para \"Yes\" (cancel√≥) y 0 para \"No\" (no cancel√≥). Tambi√©n has confirmado el desbalanceo significativo en las clases, lo cual es una observaci√≥n crucial para la fase de modelado.\n",
    "\n",
    "Ahora, procederemos con la normalizaci√≥n o estandarizaci√≥n de los datos num√©ricos. Como mencionamos, este paso es fundamental para los modelos que son sensibles a la escala de las caracter√≠sticas, como la Regresi√≥n Log√≠stica y KNN.\n",
    "\n",
    "### ‚öñÔ∏è Normalizaci√≥n o Estandarizaci√≥n de Datos\n",
    "Vamos a aplicar la estandarizaci√≥n a las columnas num√©ricas de tu DataFrame. Esto transformar√° los datos para que tengan una media de 0 y una desviaci√≥n est√°ndar de 1."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "api-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
