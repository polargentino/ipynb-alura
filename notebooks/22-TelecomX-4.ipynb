{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7dcd03bb",
   "metadata": {},
   "source": [
    "# Challenge completo con DeepSeek(15/07/2025): Pablo Mat√≠as Monsalvo\n",
    "## Primera parte de dos:\n",
    "### Challenge Telecom X: an√°lisis de evasi√≥n de clientes\n",
    "####  03 Importancia del desafio\n",
    " Siguiente pregunta\n",
    "\n",
    "### Desaf√≠o Telecom X\n",
    "El desaf√≠o Telecom X ofrece una oportunidad √∫nica para aplicar habilidades esenciales de an√°lisis de datos en un escenario de negocios real.\n",
    "\n",
    "### Aplicaci√≥n pr√°ctica del conocimiento\n",
    "La limpieza y tratamiento de datos es una habilidad fundamental para cualquier analista de datos. La manipulaci√≥n de grandes vol√∫menes de informaci√≥n exige la capacidad de identificar y corregir inconsistencias en los datos, como valores nulos, duplicados y datos fuera de est√°ndar. Garantizar que los datos est√©n listos para el an√°lisis es un paso esencial para obtener resultados precisos y confiables.\n",
    "\n",
    "El an√°lisis exploratorio de datos (EDA) es una etapa crucial para comprender en profundidad los datos. La capacidad de aplicar estad√≠sticas descriptivas y generar visualizaciones permite identificar patrones, tendencias y relaciones entre las variables. Esto ayuda a formular hip√≥tesis y generar insights que pueden influir en decisiones estrat√©gicas dentro de la empresa.\n",
    "\n",
    "Al participar en este desaf√≠o, aplicar√°s conocimientos esenciales para el an√°lisis de grandes vol√∫menes de datos en un contexto real, donde tus hallazgos podr√°n impactar directamente en las estrategias de la empresa para mejorar el principal problema que est√°n enfrentando.\n",
    "\n",
    "Este desaf√≠o no solo contribuye a tu crecimiento en el √°rea de Data Science, sino que tambi√©n ofrece la oportunidad de entender c√≥mo la ciencia de datos puede aplicarse para resolver problemas reales que enfrentan las empresas en el mercado.\n",
    "\n",
    "## Trello:\n",
    "### üí°Acerca del desaf√≠o üí°\n",
    "Descripci√≥n\n",
    "#### Telecom X - An√°lisis de Evasi√≥n de Clientes\n",
    "Has sido contratado como asistente de an√°lisis de datos en Telecom X y formar√°s parte del proyecto \"Churn de Clientes\". La empresa enfrenta una alta tasa de cancelaciones y necesita comprender los factores que llevan a la p√©rdida de clientes.\n",
    "\n",
    "Tu desaf√≠o ser√° recopilar, procesar y analizar los datos, utilizando Python y sus principales bibliotecas para extraer informaci√≥n valiosa. A partir de tu an√°lisis, el equipo de Data Science podr√° avanzar en modelos predictivos y desarrollar estrategias para reducir la evasi√≥n.\n",
    "\n",
    "¬øQu√© vas a practicar?\n",
    "‚úÖ Importar y manipular datos desde una API de manera eficiente.\n",
    "‚úÖ Aplicar los conceptos de ETL (Extracci√≥n, Transformaci√≥n y Carga) en la preparaci√≥n de los datos.\n",
    "‚úÖ Crear visualizaciones estrat√©gicas para identificar patrones y tendencias.\n",
    "‚úÖ Realizar un An√°lisis Exploratorio de Datos (EDA) y generar un informe con insights relevantes.\n",
    "\n",
    "¬°Ahora es tu turno! üöÄ Usa tus conocimientos para transformar datos en informaci√≥n estrat√©gica y ayudar a Telecom X a retener m√°s clientes.\n",
    "\n",
    "## 1-Extracci√≥n de datos:\n",
    "Descripci√≥n\n",
    "Para iniciar tu an√°lisis, necesitar√°s importar los datos de la API de Telecom X. Estos datos est√°n disponibles en formato JSON y contienen informaci√≥n esencial sobre los clientes, incluyendo datos demogr√°ficos, tipo de servicio contratado y estado de evasi√≥n.\n",
    "\n",
    "üìå Enlace de la API:\n",
    "üîó challenge2-data-science-LATAM/TelecomX_Data.json at main ¬∑ ingridcristh/challenge2-data-science-LATAM\n",
    "\n",
    "üîóGitHub - ingridcristh/challenge2-data-science-LATAM\n",
    "\n",
    "¬øQu√© debes hacer?\n",
    "‚úÖ Cargar los datos directamente desde la API utilizando Python.\n",
    "‚úÖ Convertir los datos a un DataFrame de Pandas para facilitar su manipulaci√≥n.\n",
    "\n",
    "Este es el primer paso para transformar los datos en informaci√≥n valiosa. ¬øListo para programar? üöÄ\n",
    "\n",
    "## 2 - Conoce el conjunto de datos\n",
    "Descripci√≥n\n",
    "Ahora que has extra√≠do los datos, es fundamental comprender la estructura del dataset y el significado de sus columnas. Esta etapa te ayudar√° a identificar qu√© variables son m√°s relevantes para el an√°lisis de evasi√≥n de clientes.\n",
    "\n",
    "üìå Para facilitar este proceso, hemos creado un diccionario de datos con la descripci√≥n de cada columna. Aunque no es obligatorio utilizarlo, puede ayudarte a comprender mejor la informaci√≥n disponible.\n",
    "\n",
    "üîó Enlace al diccionario y a la API\n",
    "\n",
    "¬øQu√© debes hacer?\n",
    "‚úÖ Explorar las columnas del dataset y verificar sus tipos de datos.\n",
    "‚úÖ Consultar el diccionario para comprender mejor el significado de las variables.\n",
    "‚úÖ Identificar las columnas m√°s relevantes para el an√°lisis de evasi√≥n.\n",
    "\n",
    "üìå Tips:\n",
    "üîó Documentaci√≥n de DataFrame.info()\n",
    "üîó Documentaci√≥n de DataFrame.dtypes\n",
    "\n",
    "## 3 - Comprobaci√≥n de incoherencias en los datos\n",
    "Descripci√≥n\n",
    "En este paso, verifica si hay problemas en los datos que puedan afectar el an√°lisis. Presta atenci√≥n a valores ausentes, duplicados, errores de formato e inconsistencias en las categor√≠as. Este proceso es esencial para asegurarte de que los datos est√©n listos para las siguientes etapas.\n",
    "\n",
    "üìå Tips:\n",
    "\n",
    "üîó Documentaci√≥n de pandas.unique()\n",
    "üîó Documentaci√≥n de pandas.Series.dt.normalize()\n",
    "\n",
    "## 4 - Manejo de inconsistencias\n",
    "Descripci√≥n\n",
    "Ahora que has identificado las inconsistencias, es momento de aplicar las correcciones necesarias. Ajusta los datos para asegurarte de que est√©n completos y coherentes, prepar√°ndolos para las siguientes etapas del an√°lisis.\n",
    "\n",
    "üìå Tips:\n",
    "\n",
    "üîó Manipulaci√≥n de strings en pandas: lower, replace, startswith y contains | Alura Cursos Online\n",
    "\n",
    "\n",
    "## 5 - Columna de cuentas diarias\n",
    "Descripci√≥n\n",
    "Ahora que los datos est√°n limpios, es momento de crear la columna \"Cuentas_Diarias\". Utiliza la facturaci√≥n mensual para calcular el valor diario, proporcionando una visi√≥n m√°s detallada del comportamiento de los clientes a lo largo del tiempo.\n",
    "\n",
    "üìå Esta columna te ayudar√° a profundizar en el an√°lisis y a obtener informaci√≥n valiosa para las siguientes etapas.\n",
    "\n",
    "## 6 - Estandarizaci√≥n y transformaci√≥n de datos (opcional)\n",
    "Descripci√≥n\n",
    "La estandarizaci√≥n y transformaci√≥n de datos es una etapa opcional, pero altamente recomendada, ya que busca hacer que la informaci√≥n sea m√°s consistente, comprensible y adecuada para el an√°lisis. Durante esta fase, por ejemplo, puedes convertir valores textuales como \"S√≠\" y \"No\" en valores binarios (1 y 0), lo que facilita el procesamiento matem√°tico y la aplicaci√≥n de modelos anal√≠ticos.\n",
    "\n",
    "Adem√°s, traducir o renombrar columnas y datos hace que la informaci√≥n sea m√°s accesible y f√°cil de entender, especialmente cuando se trabaja con fuentes externas o t√©rminos t√©cnicos. Aunque no es un paso obligatorio, puede mejorar significativamente la claridad y comunicaci√≥n de los resultados, facilitando la interpretaci√≥n y evitando confusiones, especialmente al compartir informaci√≥n con stakeholders no t√©cnicos.\n",
    "\n",
    "## 7 - Carga y an√°lisis(L - Load & Analysis)\n",
    "### An√°lisis Descriptivo\n",
    "Descripci√≥n\n",
    "Para comenzar, realiza un an√°lisis descriptivo de los datos, calculando m√©tricas como media, mediana, desviaci√≥n est√°ndar y otras medidas que ayuden a comprender mejor la distribuci√≥n y el comportamiento de los clientes.\n",
    "\n",
    "üìå Consejos:\n",
    "\n",
    "üîó Documentaci√≥n de DataFrame.describe()\n",
    "\n",
    "## 8 - Distribuci√≥n de evasi√≥n\n",
    "Descripci√≥n\n",
    "En este paso, el objetivo es comprender c√≥mo est√° distribuida la variable \"churn\" (evasi√≥n) entre los clientes. Utiliza gr√°ficos para visualizar la proporci√≥n de clientes que permanecieron y los que se dieron de baja.\n",
    "\n",
    "## 9 - Recuento de evasi√≥n por variables categ√≥ricas\n",
    "Descripci√≥n\n",
    "Ahora, exploraremos c√≥mo se distribuye la evasi√≥n seg√∫n variables categ√≥ricas, como g√©nero, tipo de contrato, m√©todo de pago, entre otras.\n",
    "\n",
    "Este an√°lisis puede revelar patrones interesantes, por ejemplo, si los clientes de ciertos perfiles tienen una mayor tendencia a cancelar el servicio, lo que ayudar√° a orientar acciones estrat√©gicas.\n",
    "\n",
    "## 10 - Conteo de evasi√≥n por variables num√©ricas\n",
    "Descripci√≥n\n",
    "En este paso, explora c√≥mo las variables num√©ricas, como \"total gastado\" o \"tiempo de contrato\", se distribuyen entre los clientes que cancelaron (evasi√≥n) y los que no cancelaron.\n",
    "\n",
    "Este an√°lisis ayuda a entender si ciertos valores num√©ricos est√°n m√°s asociados con la evasi√≥n, proporcionando insights sobre los factores que influyen en el comportamiento de los clientes.\n",
    "\n",
    "## 11 - Informe final\n",
    "Descripci√≥n\n",
    "Finaliza el desaf√≠o elaborando un informe dentro del mismo notebook que resuma todo el trabajo realizado. El informe debe incluir:\n",
    "\n",
    "üîπ Introducci√≥n: Explica el objetivo del an√°lisis y el problema de evasi√≥n de clientes (Churn).\n",
    "\n",
    "üîπ Limpieza y Tratamiento de Datos: Describe los pasos realizados para importar, limpiar y procesar los datos.\n",
    "\n",
    "üîπ An√°lisis Exploratorio de Datos: Presenta los an√°lisis realizados, incluyendo gr√°ficos y visualizaciones para identificar patrones.\n",
    "\n",
    "üîπ Conclusiones e Insights: Resume los principales hallazgos y c√≥mo estos datos pueden ayudar a reducir la evasi√≥n.\n",
    "\n",
    "üîπ Recomendaciones: Ofrece sugerencias estrat√©gicas basadas en tu an√°lisis.\n",
    "\n",
    "Aseg√∫rate de que el informe est√© bien estructurado, claro y respaldado por visualizaciones que refuercen tus conclusiones. üöÄ\n",
    "\n",
    "\n",
    "## 12 - ¬°Extra! An√°lisis de correlaci√≥n entre variables\n",
    "Descripci√≥n\n",
    "Esta actividad es un extra, por lo tanto es OPCIONAL.\n",
    "\n",
    "Como un paso adicional, puedes explorar la correlaci√≥n entre diferentes variables del dataset. Esto puede ayudar a identificar qu√© factores tienen mayor relaci√≥n con la evasi√≥n de clientes, como:\n",
    "\n",
    "üîπ La relaci√≥n entre la cuenta diaria y la evasi√≥n.\n",
    "üîπ C√≥mo la cantidad de servicios contratados afecta la probabilidad de churn.\n",
    "\n",
    "Puedes usar la funci√≥n corr() de Pandas para calcular las correlaciones y visualizar los resultados con gr√°ficos de dispersi√≥n o matrices de correlaci√≥n.\n",
    "\n",
    "Este an√°lisis adicional puede proporcionar insights valiosos para la creaci√≥n de modelos predictivos m√°s robustos. üöÄ\n",
    "\n",
    "## 13 - üìñ README üìñ\n",
    "Descripci√≥n\n",
    "El README es un elemento clave en cualquier proyecto de desarrollo, ya que proporciona una descripci√≥n clara y detallada del prop√≥sito, la estructura y el uso del c√≥digo.\n",
    "\n",
    "Cuando participas en un proceso de selecci√≥n, el README es imprescindible para comunicar c√≥mo utilizar el proyecto.\n",
    "\n",
    "Este archivo, con la extensi√≥n .md (Markdown), es el punto de referencia inicial para cualquiera que quiera entender y trabajar con su c√≥digo.\n",
    "\n",
    "Un buen README incluye informaci√≥n sobre la instalaci√≥n, dependencias, c√≥mo ejecutar el proyecto y posibles problemas o soluciones.\n",
    "\n",
    "Un README bien estructurado facilita que otros desarrolladores comprendan el proyecto.\n",
    "\n",
    "Aqu√≠ hay un art√≠culo con los pasos para crear un README incre√≠ble:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d77ab5",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a34a024",
   "metadata": {},
   "source": [
    "# Segunda parte: 2/2\n",
    "## Telecom X ‚Äì Parte 2: Predicci√≥n de Cancelaci√≥n (Churn)\n",
    "üì£ Historia del Desaf√≠o\n",
    "\n",
    "¬°Felicidades! üéâ Has sido promovido despu√©s de tu excelente desempe√±o en el an√°lisis exploratorio de la cancelaci√≥n de clientes en Telecom X. Tu dedicaci√≥n, claridad al comunicar los datos y visi√≥n estrat√©gica marcaron la diferencia.\n",
    "\n",
    "Ahora, ¬°has sido invitado oficialmente a formar parte del equipo de Machine Learning de la empresa!\n",
    "\n",
    "üéØ Misi√≥n\n",
    "\n",
    "Tu nueva misi√≥n es desarrollar modelos predictivos capaces de prever qu√© clientes tienen mayor probabilidad de cancelar sus servicios.\n",
    "\n",
    "La empresa quiere anticiparse al problema de la cancelaci√≥n, y te corresponde a ti construir un pipeline robusto para esta etapa inicial de modelado.\n",
    "\n",
    "üß† Objetivos del Desaf√≠o\n",
    "\n",
    "Preparar los datos para el modelado (tratamiento, codificaci√≥n, normalizaci√≥n).\n",
    "\n",
    "Realizar an√°lisis de correlaci√≥n y selecci√≥n de variables.\n",
    "\n",
    "Entrenar dos o m√°s modelos de clasificaci√≥n.\n",
    "\n",
    "Evaluar el rendimiento de los modelos con m√©tricas.\n",
    "\n",
    "Interpretar los resultados, incluyendo la importancia de las variables.\n",
    "\n",
    "Crear una conclusi√≥n estrat√©gica se√±alando los principales factores que influyen en la cancelaci√≥n.\n",
    "\n",
    "üß∞ Lo que vas a practicar\n",
    "\n",
    "‚úÖ Preprocesamiento de datos para Machine Learning\n",
    "‚úÖ Construcci√≥n y evaluaci√≥n de modelos predictivos\n",
    "‚úÖ Interpretaci√≥n de resultados y entrega de insights\n",
    "‚úÖ Comunicaci√≥n t√©cnica con enfoque estrat√©gico\n",
    "\n",
    "üöÄ Ahora eres: Analista Junior de Machine Learning\n",
    "\n",
    "Telecom X conf√≠a en tu entrega para dar los pr√≥ximos pasos hacia una soluci√≥n de inteligencia predictiva eficaz. ¬°Buena suerte!\n",
    "\n",
    "\n",
    "## 1- Extracci√≥n del Archivo Tratado\n",
    "Descripci√≥n\n",
    "Carga el archivo CSV que contiene los datos tratados anteriormente.\n",
    "üìÇ Atenci√≥n: Utiliza el mismo archivo que limpiaste y organizaste en la Parte 1 del desaf√≠o Telecom X. Debe contener solo las columnas relevantes, ya con los datos corregidos y estandarizados.\n",
    "\n",
    "## 2 - Eliminaci√≥n de Columnas Irrelevantes\n",
    "Descripci√≥n\n",
    "Elimina columnas que no aportan valor al an√°lisis o a los modelos predictivos, como identificadores √∫nicos (por ejemplo, el ID del cliente). Estas columnas no ayudan en la predicci√≥n de la cancelaci√≥n y pueden incluso perjudicar el desempe√±o de los modelos.\n",
    "\n",
    "## 3 - Encoding\n",
    "Descripci√≥n\n",
    "Transforma las variables categ√≥ricas a formato num√©rico para hacerlas compatibles con los algoritmos de machine learning. Utiliza un m√©todo de codificaci√≥n adecuado, como one-hot encoding.\n",
    "\n",
    "üîé Sugerencia:\n",
    "Puedes consultar este art√≠culo para entender mejor cu√°ndo usar get_dummies o OneHotEncoder:\n",
    "Art√≠culo en Alura sobre codificaci√≥n categ√≥rica\n",
    "\n",
    "## 4 - Verificaci√≥n de la Proporci√≥n de Cancelaci√≥n (Churn)\n",
    "Descripci√≥n\n",
    "Calcula la proporci√≥n de clientes que cancelaron en relaci√≥n con los que permanecieron activos. Eval√∫a si existe un desbalance entre las clases, ya que esto puede impactar en los modelos predictivos y en el an√°lisis de los resultados.\n",
    "\n",
    "üîé Sugerencia:\n",
    "Puedes usar value_counts() de pandas para obtener esta proporci√≥n:\n",
    "Documentaci√≥n oficial de value_counts()\n",
    "\n",
    "## 5 - Balanceo de Clases (opcional)\n",
    "Descripci√≥n\n",
    "Si deseas profundizar en el an√°lisis, aplica t√©cnicas de balanceo como undersampling o oversampling. En situaciones de fuerte desbalanceo, herramientas como SMOTE pueden ser √∫tiles para generar ejemplos sint√©ticos de la clase minoritaria.\n",
    "\n",
    "üîé Sugerencia:\n",
    "Puedes leer m√°s sobre c√≥mo manejar el desbalanceo de clases en este art√≠culo:\n",
    "Art√≠culo en Alura sobre desbalanceo de datos\n",
    "\n",
    "## 6 - Normalizaci√≥n o Estandarizaci√≥n (si es necesario)\n",
    "Eval√∫a la necesidad de normalizar o estandarizar los datos, seg√∫n los modelos que se aplicar√°n. Modelos basados en distancia, como KNN, SVM, Regresi√≥n Log√≠stica y Redes Neuronales, requieren este preprocesamiento. Por otro lado, modelos basados en √°rboles, como Decision Tree, Random Forest y XGBoost, no son sensibles a la escala de los datos.\n",
    "\n",
    "üîé Sugerencia:\n",
    "Puedes leer m√°s sobre normalizaci√≥n y estandarizaci√≥n de datos en este art√≠culo:\n",
    "Art√≠culo en Medium sobre normalizaci√≥n y estandarizaci√≥n en Machine Learning\n",
    "\n",
    "## 7 - üéØ Correlaci√≥n y Selecci√≥n de Variables\n",
    "### An√°lisis de Correlaci√≥n\n",
    "#### Descripci√≥n\n",
    "Visualiza la matriz de correlaci√≥n para identificar relaciones entre las variables num√©ricas. Presta especial atenci√≥n a las variables que muestran una mayor correlaci√≥n con la cancelaci√≥n, ya que estas pueden ser fuertes candidatas para el modelo predictivo.\n",
    "\n",
    "## 8 - An√°lisis Dirigido\n",
    "Descripci√≥n\n",
    "Investiga c√≥mo variables espec√≠ficas se relacionan con la cancelaci√≥n, tales como:\n",
    "\n",
    "Tiempo de contrato √ó Cancelaci√≥n\n",
    "\n",
    "Gasto total √ó Cancelaci√≥n\n",
    "\n",
    "Utiliza gr√°ficos como boxplots o scatter plots para visualizar patrones y posibles tendencias.\n",
    "\n",
    "## 9 - ü§ñ Modelado Predictivo\n",
    "### Separaci√≥n de Datos\n",
    "Descripci√≥n\n",
    "Divide el conjunto de datos en entrenamiento y prueba para evaluar el rendimiento del modelo. Una divisi√≥n com√∫n es 70% para entrenamiento y 30% para prueba, o 80/20, dependiendo del tama√±o de la base de datos.\n",
    "\n",
    "## 10 - Creaci√≥n de Modelos\n",
    "Descripci√≥n\n",
    "Crea al menos dos modelos diferentes para predecir la cancelaci√≥n de clientes.\n",
    "\n",
    "Un modelo puede requerir normalizaci√≥n, como Regresi√≥n Log√≠stica o KNN.\n",
    "\n",
    "El otro modelo puede no requerir normalizaci√≥n, como √Årbol de Decisi√≥n o Random Forest.\n",
    "\n",
    "üí° La decisi√≥n de aplicar o no la normalizaci√≥n depende de los modelos seleccionados. Ambos modelos pueden ser creados sin normalizaci√≥n, pero tambi√©n es una opci√≥n combinar modelos con y sin normalizaci√≥n.\n",
    "\n",
    "#### Justificaci√≥n:\n",
    "\n",
    "* Regresi√≥n Log√≠stica / KNN: Estos modelos son sensibles a la escala de los datos, por lo que la normalizaci√≥n es importante para que los coeficientes o las distancias se calculen correctamente.\n",
    "\n",
    "* √Årbol de Decisi√≥n / Random Forest: Estos modelos no dependen de la escala de los datos, por lo que no es necesario aplicar normalizaci√≥n.\n",
    "\n",
    "Si decides normalizar los datos, deber√≠as explicar c√≥mo esta etapa asegura que los modelos basados en distancia o en optimizaci√≥n de par√°metros no se vean sesgados por la magnitud de las variables.\n",
    "\n",
    "\n",
    "## 11 - Evaluaci√≥n de los Modelos\n",
    "Descripci√≥n\n",
    "Eval√∫a cada modelo utilizando las siguientes m√©tricas:\n",
    "\n",
    "* Exactitud (Acur√°cia)\n",
    "\n",
    "* Precisi√≥n\n",
    "\n",
    "* Recall\n",
    "\n",
    "* F1-score\n",
    "\n",
    "* Matriz de confusi√≥n\n",
    "\n",
    "Despu√©s, realiza un an√°lisis cr√≠tico y compara los modelos:\n",
    "\n",
    "* ¬øCu√°l modelo tuvo el mejor desempe√±o?\n",
    "\n",
    "* ¬øAlg√∫n modelo present√≥ overfitting o underfitting? Si es as√≠, considera las posibles causas y ajustes:\n",
    "\n",
    "**Overfitting**: Cuando el modelo aprende demasiado sobre los datos de entrenamiento, perdiendo la capacidad de generalizar a nuevos datos. Considera reducir la complejidad del modelo o aumentar los datos de entrenamiento.\n",
    "\n",
    "**Underfitting**: Cuando el modelo no captura bien las tendencias de los datos, lo que indica que es demasiado simple. Intenta aumentar la complejidad del modelo o ajustar sus par√°metros.\n",
    "\n",
    "## üìã 12 - Interpretaci√≥n y Conclusiones\n",
    "### An√°lisis de la Importancia de las Variables\n",
    "Descripci√≥n\n",
    "Despu√©s de elegir los modelos, realiza el an√°lisis de las variables m√°s relevantes para la predicci√≥n de la cancelaci√≥n:\n",
    "\n",
    "* Regresi√≥n Log√≠stica: Investiga los coeficientes de las variables, que muestran su contribuci√≥n a la predicci√≥n de cancelaci√≥n.\n",
    "\n",
    "* KNN (K-Nearest Neighbors): Observa c√≥mo los vecinos m√°s cercanos influyen en la decisi√≥n de clasificaci√≥n. Las variables m√°s impactantes pueden ser aquellas que m√°s contribuyen a la proximidad entre los puntos de datos.\n",
    "\n",
    "* Random Forest: Utiliza la importancia de las variables proporcionada por el modelo. Random Forest calcula la importancia bas√°ndose en c√≥mo cada variable contribuye a la reducci√≥n de la impureza durante las divisiones de los √°rboles.\n",
    "\n",
    "* SVM (Support Vector Machine): En el SVM, las variables m√°s relevantes son aquellas que influyen en la frontera de decisi√≥n entre las clases. Puedes analizar los coeficientes de los vectores de soporte para entender qu√© variables tienen mayor impacto.\n",
    "\n",
    "* Otros Modelos: Dependiendo del modelo elegido, considera el an√°lisis de m√©tricas espec√≠ficas para comprender la relevancia de las variables. Por ejemplo, coeficientes en modelos lineales, pesos en redes neuronales, o la importancia relativa en t√©cnicas de boosting (como XGBoost).\n",
    "\n",
    "## 13 - Conclusi√≥n\n",
    "Descripci√≥n\n",
    "Elaboren un informe detallado, destacando los factores que m√°s influyen en la cancelaci√≥n, bas√°ndose en las variables seleccionadas y en el rendimiento de cada modelo.\n",
    "\n",
    "Identifiquen los principales factores que afectan la cancelaci√≥n de clientes y propongan estrategias de retenci√≥n basadas en los resultados obtenidos.\n",
    "\n",
    "## ruta:\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Ruta al archivo local\n",
    "ruta_archivo = '../data/TelecomX_Data.json'"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
